---
title: "script_analyse_test"
author: "Hugo Gallier"
date: "2024-01-23"
output: html_document
editor_options: 
  chunk_output_type: console
---


# Library

Package à télécharger
```{r}
rm(list=ls())

library(dplyr)
library(tidyr)
library(ggplot2)
library(here)
library(vegan)
library(scales)
library(fmsb)
library(FactoMineR)
library(ecodist)
library(ade4)
library(lme4)
library(Matrix)
library(sjPlot)
library(RColorBrewer)
library(iNEXT)
library(rstatix)
library(ggradar)
library(pairwiseAdonis)
library(ecole)
library(tidyverse)
library(mgcv)
library(ggforce)
library(tidymv)
library(ggtern)
library(codyn)
library(adespatial)
library(ggdendro)
library(car)

```


#################### Importation du data et chargement ###################

```{r}
#Chargement des photos associées à chaque cadrats

setwd(here::here())

MPhoto=read.csv('Meta_photo.csv', sep=';')%>%
  # mutate(Micro=) %>%
  mutate(Micro=sub("\\_.*", "", Code_struct))
  
```

## Chargement data

```{r}
#Chargement des jeux de données

setwd('D:/Hugo/suivi_scientifique') # à modifier avec nom de ton DD
# setwd('E:/Marineff/suivi_scientifique')

data_list=list.files(pattern =".csv", recursive=T)

L=list()
for( i in 1: length(data_list)){
  
    Name_file=basename(data_list[i])

data=read.csv(data_list[i], sep=',', header=T, fileEncoding="latin1") %>%
  mutate(Name_file=rep(basename(data_list[i]), n()))

L[[i]]<-data
}


test_data_list=data_list[grepl('DSC',data_list)]


# fileEncoding="latin1"
```

## Date d'immersion

```{r}
# Ajout des dates d'immersion des différents récifs

Immer_site=data.frame(Site=c('Bi','Bu','VB','Fe'), Date=c(as.Date('2020-10-30'),as.Date('2020-11-26'),as.Date('2020-11-27'),as.Date('2020-11-30'))) %>%
       mutate(Date_imm_ok=format(as.POSIXlt(Date,  format = "%Y-%m-%d"), format="%Y-%m-%d", tz="GMT")) %>% select(Site, Date_imm_ok)
     
# Date=c(as.Date('2020-10-30'),as.Date('2020-11-26'),as.Date('2020-11-27'),as.Date('2020-11-30'))) %>%
       # mutate(Date_imm_ok=format(as.POSIXlt(Date,  format = "%Y-%m-%d"), format="%Y-%m-%d %%H:%M:%S", tz="GMT")) %>% select(Site, Date_imm_ok)    
```


## Saison - date

```{r}
# Ajout de dates correspondant aux différentes saisons
Date_sais=data.frame(
           start=c(
             format(as.POSIXlt(as.Date('2021-03-20'),  format = "%Y-%m-%d"), format="%Y-%m-%d %%H:%M:%S", tz="GMT"),
             format(as.POSIXlt(as.Date('2021-06-21'),  format = "%Y-%m-%d"), format="%Y-%m-%d %%H:%M:%S", tz="GMT"),
             format(as.POSIXlt(as.Date('2021-09-22'),  format = "%Y-%m-%d"), format="%Y-%m-%d %%H:%M:%S", tz="GMT"),
             format(as.POSIXlt(as.Date('2021-12-21'),  format = "%Y-%m-%d"), format="%Y-%m-%d %%H:%M:%S", tz="GMT"),
      format(as.POSIXlt(as.Date('2022-03-20'),  format = "%Y-%m-%d"), format="%Y-%m-%d %%H:%M:%S", tz="GMT"),
      format(as.POSIXlt(as.Date('2022-06-21'),  format = "%Y-%m-%d"), format="%Y-%m-%d %%H:%M:%S", tz="GMT"),
       format(as.POSIXlt(as.Date('2022-09-22'),  format = "%Y-%m-%d"), format="%Y-%m-%d %%H:%M:%S", tz="GMT")))
```



## Mise en forme des données

```{r}
# Ajout de méta données à partir du nom de fichier (site,data,micro,n° de quadrat)
# Correction et abbréviation des noms de taxons
# Changements des noms des microhabitats
# Changements du format des dates


# test_dataPQ=data_PQ[grepl('DSC',data_PQ$Name_file),]

data_PQ=do.call(rbind,L) %>%
  mutate(Site=substr(Name_file, start = 1, stop = 2)) %>%
  separate(col = Name_file, into = c('Site','Date','Micro','truc','Quad'), sep = '_') %>%
  mutate( Site=ifelse(Site=='FR','Fe',Site),
          Quad=ifelse(is.na(Quad),truc,Quad),
          Quad2=substr(Quad, start = 1, stop = 2),
          Month_str=gsub("-.*", "", Date,perl=TRUE),
          YY=gsub(".*-", "", Date,perl=TRUE),
          Month=case_when( Month_str=='Avri'~'04',
                           Month_str=='avri'~'04',
                           Month_str=="Janv"~'01',
                           Month_str=='Juil'~'07',
                           Month_str=='Oct'~'10',
                           Month_str=='Nov'~'11'),
          Date_ok=format(as.POSIXlt(paste0('01/',Month,'/',YY),  format = "%d/%m/%y"), format="%Y-%m-%d %%H:%M:%S", tz="GMT"),
          Date_courte=format(as.POSIXlt(paste0('01/',Month,'/',YY),  format = "%d/%m/%y"), format="%Y-%m", tz="GMT"),
          Week=strftime(Date_ok, format = "%V")) %>%
  mutate(spp.Name= ifelse(spp.Name == 'Tubularia indivisa ', 'Tubularia indivisa',spp.Name),
         spp.Name=ifelse(spp.Name == 'Unidentified','NI',spp.Name))
  



# Version synthétique du df

data_PQ_light=data_PQ %>% dplyr::select(Image, spp.Name,spp.ID,N.pts.per.species,Cov..per.species,
               N.pts.ALL.species,Cov..ALL.species, Site,Date_ok,Micro,Quad2,
               Week,Date_courte,Month_str )%>%
rename('spp'='spp.Name',
       'Count'='N.pts.per.species',
       'Cov'='Cov..per.species',
       'Count_all'='N.pts.ALL.species',
       'Cov_all'='Cov..ALL.species')%>%
  mutate(abb=abbreviate(spp))%>%
   group_by(spp,abb,Site,Micro,Date_courte,Date_ok,Quad2) %>%
  summarize(Mcov=mean(Cov)) %>%
  # summarize(MCount=mean(Count)) %>%
  left_join(MPhoto, by=c('Micro')) %>%
  mutate(Structure2=recode_factor(Structure,
   "Bandes"="Dome",
   "Bandes.C1"="Disc",
   "Faille"="Inner_slots",
   "Faille_coupole"="Upper_slots",
   "Pilier.C2"="Columns",
   "Trous"="Holes",
   "Pieds"="Pillars"))%>% 
  mutate(Strcut_groups=case_when(
  Structure2 %in% c('Dome','Upper_slots')~'Horizontal_section',
 Structure2 %in% c('Disc','Columns','Pillars')~'Vertical_section',
  Structure2 %in% c('Inner_slots','Holes')~'Inner_section', TRUE ~ 'NA')) %>%
  mutate(M_ensemble=ifelse(Micro %in% c("P1","P2","P3","T1","T2","T3","T4"),substr(Micro, start = 1, stop = 1),substr(Micro, start = 1, stop = 3)),
         M_ensemble2=ifelse(M_ensemble == 'DPF','DGF',M_ensemble))%>%
  left_join(Immer_site, by='Site') %>% 
    mutate(spp=replace_na(spp,"None"))
 

knitr::kable(data_PQ_light %>% select(spp,abb)%>% unique())
corresp=data_PQ_light %>% select(spp,abb)%>% unique()
```



# #######################

# ###### Partie Hugo ######
# Formatage du jeu de données 
```{r}
#Calcul du temps depuis l'immersion
data_PQ_light=data_PQ_light %>% 
   mutate(Day_delta=as.numeric(difftime(Date_ok,Date_imm_ok,units='days')))

dataR1<-data_PQ_light
dataR=dataR1 %>% filter(!spp %in% c("NI","Unassigned","ponte","Ponte",'None','NA')) %>%
  filter(!Micro %in% c('C2P3.rndpts.csv','C2P4.rndpts.csv','C2P6.rndpts.csv')) %>% 
  filter(!Site == ("DSC"))%>%
  filter(!Structure2 %in% c('Holes','Upper_slots','Dome')) %>% 
  filter(!Date_courte == '2021-01') %>% 
  select (spp,abb,Site,Micro,Date_courte,Structure2,Mcov,Day_delta,Quad2)
  # select (spp,abb,Site,Micro,Date_courte,Structure2,MCount)

# save(dataR,file="dataR.Rdata")



#####permet de faire la moyenne du nombre de taxon dans chaque micro
# dataR2=dataR %>% ungroup %>% 
#   select(spp,Site,Structure2,Micro,Date_courte) %>% 
#   distinct()%>% 
#   group_by(Site,Structure2,Micro,Date_courte) %>% 
#   summarize(S=n()) %>%
#   na.omit()
# 
# dataR3=dataR2 %>% 
#   group_by(Site,Structure2,Date_courte) %>% 
#   summarize(mean__count = mean(S))
# 
# 
#####permet de faire la moyenne du nombre de taxon dans chaque structure 
# dataR2=dataR %>% ungroup %>% 
#   select(spp,Site,Structure2,Date_courte) %>% 
#   distinct()%>% 
#   group_by(Site,Structure2,Date_courte) %>% 
#   summarize(S=n()) %>%
#   na.omit()
# 
# dataR3=dataR2 %>% 
#   group_by(Site,Date_courte) %>% 
#   summarize(mean__count = mean(S))

```


# ### Indice Gamma
```{r}
# Quel est la richesse taxonomique global (Indice Gamma) d'un site et de la zone d'étude en général

# Indice gamma par site 
dataR2=dataR %>% ungroup %>% 
  select(spp,Site,Date_courte) %>% 
  filter(Date_courte  %in% c('2021-04','2021-07','2021-10','2021-11')) %>%
  filter(Site == "Fe") %>%
  distinct()%>% 
  group_by(spp,Date_courte,Site) %>% 
  summarize(S=n()) %>%
  na.omit()
length(unique(dataR2$spp))


seq<-rep(0,times=nrow(dataR))
dataR
dataR2=dataR %>% 
  select(spp,Site) %>% 
  distinct() %>% 
  group_by(spp,Site) %>% 
  summarize(S=n()) 
length(unique(dataR2$spp))


# Indice gamma Quad2# Indice gamma global
dataR2=dataR %>% 
  select(spp,seq1) %>% 
  distinct() %>% 
  group_by(seq1) %>% 
  summarize(S=n()) 


length(unique(dataR1$spp))#permet de savoir le nombre de variable différente dans la colonne spp (mais ne prend pas en compte la suppression des N)

```


# ### Indice Alpha 


# Comparaison intersite et intrasite
## Comparaison intersite 2021-2022 (pas de temporalité saisonalle)
```{r}
#Y'a t'il une différence de richesse taxonomique entre les différents micro habitats, et selon les différents sites ainsi que selon les années?

#permet de faire la moyenne du nombre de taxon dans chaque micro
dataR2=dataR %>% ungroup %>% 
  select(spp,Site,Structure2,Micro,Date_courte) %>% 
  distinct()%>% 
  group_by(Site,Structure2,Micro,Date_courte) %>% 
  summarize(S=n()) %>%
  na.omit()

dataR3=dataR2 %>% 
  group_by(Site,Structure2,Date_courte) %>% 
  summarize(S2 = mean(S))
dataR3$S2[which(dataR3$Structure2=='Pillars')]<-(dataR3$S2[which(dataR3$Structure2=='Pillars')]/2)

ggplot(dataR3, aes(Structure2,S2, fill=Site))+ # Avec "fill" ou "col" du peut ajout une séparation de tes données par facteur (ici le site)
  xlab("Structure")+
  ylab("Richesse taxonomique")+
  geom_jitter(alpha=.3)+  # On ajoute les points (pas nécessaire mais utile pour savoir sur quoi se base les boxplots)
  geom_boxplot()+
  theme_bw()  # Juste pour retirer le fond gris pas défaut (--> moche !)

```

###Test Shapiro/Levene/Anova
```{r}
# Y'a t-il des différences statistiques concerannt les sites/structurse/microhabitats,... ?

dataR$saison<-dataR$Date_courte
dataR$saison[dataR$saison == "2021-04" | dataR$saison == "2022-04"] <- "printemps"
dataR$saison[dataR$saison == "2021-07" | dataR$saison == "2022-07"] <- "été"
dataR$saison[dataR$saison == "2021-10" | dataR$saison == "2021-11"| dataR$saison == "2022-11"] <- "automne"
dataR$saison[dataR$saison == "2022-01"] <- "hiver"

dataR2=dataR %>% ungroup %>% 
  # filter(Date_courte %in% c("2021-04","2021-07","2021-10","2021-11")) %>% 
  select(spp,Site,Structure2,Micro,Day_delta,saison) %>% 
  distinct()%>% 
  group_by(Site,Structure2,Micro,Day_delta,saison) %>% 
  summarize(S=n()) %>%
  na.omit()

dataR3=dataR2 %>% 
  group_by(Site,Structure2,Day_delta,saison) %>% 
  summarize(S2 = mean(S))

test_levene<-levene_test(dataR3$S2~dataR3$Site+Structure2+dataR3$saison)
#normalité des données
shapiro_test(residuals(test_anova))#si pvalue supérieure à 0,05 alors permet de dire que les résidus sont normalements distribuées
# qqnorm(test_anova$residuals)
# qqline(test_anova$residuals)


#Homoscédasticité
leveneTest(test_anova$residuals,dataR3)#Si p value supérieur à 0,05 alors variance entre les groupes est égale
plot(test_anova$residuals~test_anova$fitted.values)

test_anova<-aov(S2~Site+Structure2+saison,data=dataR3)#anova en prenant la date ainsi que les structures comme facteur

summary(test_anova)

```

## Comparaison intersite (microhabitats confondus) temporelle
```{r}
# Comment évolue la richesse taxonomique des sites dans le temps?

#permet de faire la moyenne du nombre de taxon dans chaque micro
dataR2=dataR %>% ungroup %>% 
  select(spp,Site,Structure2,Date_courte) %>% 
  distinct()%>% 
  group_by(Site,Structure2,Date_courte) %>% 
  summarize(S=n()) %>%
  na.omit()

dataR3=dataR2 %>% 
  group_by(Site,Date_courte) %>% 
  summarize(S2 = mean(S))


ggplot(dataR3, aes(Date_courte,S2, col=Site))+
  xlab("Date")+
  ylab("Richesse taxonomique")+
  geom_point()+
  geom_line(aes(group=Site))+
  # facet_wrap(.~Site)+ # <- cette fonction permet de réaliser les geoms précedents mais pour différentes catégories (ici j'ai choisi les micro habitat, mais on aurait pu le faire pour les sites par exemples)
  theme_bw()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) # <- rotation des dates pour qu'elles soient lisibles

```

## Comparaison intersite des microhabitats - temporelle
```{r}
# Y'a t'il une différence temporelle dans l'évolution de la richesse taxnomique des microhabitats?

dataR2=dataR %>% ungroup %>% 
  filter(!Date_courte=="2021-01") %>%
  select(spp,Site,Date_courte,Structure2) %>% 
  distinct() %>% 
  group_by(Site,Date_courte,Structure2) %>% 
  summarize(S=n()) %>% 
  na.omit()


ggplot(dataR2 %>%  
  filter(!Date_courte=="2021-01"), 
  aes(Date_courte,S, col=Site))+
  xlab("Date")+
  ylab("Richesse taxonomique")+
  geom_point()+
  geom_line(aes(group=Site))+
  facet_wrap(.~Structure2)+ 
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) 

```

# Radar plot
```{r}
#Y a t'il une colonisation prédominante sur les différentes parties des récifs?

# https://r-charts.com/ranking/ggradar/
# devtools::install_github("ricardo-bion/ggradar")


##### Bottom disc #####
lcol2<-brewer.pal(8,"Reds")
lcol2<-c('#FEE0D2','#FCBBA1','#FC9272','#FB6A4A','#EF3B2C','#CB181D','#99000D','#59040c')

# Bi
resultat4Bi<- na.omit(spread((dataR2=dataR %>% 
  filter(!Date_courte == ("2021-01"))%>%
  filter(Site == ("Bi"))%>%
  filter(Micro %in% c("C1B1","C1B2","C1B3","C1B4","C1B5","C1B6","C1B7","C1B8"))%>%
  select(spp,Site,Date_courte,Micro) %>% 
  distinct() %>% 
  group_by(Site,Date_courte,Micro) %>% 
  summarize(S=n())),key=Micro,value=S)) 
resultat4Bi[is.na(resultat4Bi)]<-0

ggradar(resultat4Bi[,-1],grid.min = 0,grid.mid=7,grid.max =15,values.radar = c(0,7,15),group.colours = lcol2[c(1,2,4:8)],legend.title="Site Bi",gridline.max.linetype = 1,gridline.max.colour = "black",gridline.min.linetype = 1,gridline.min.colour="black",gridline.mid.linetype = 1,gridline.mid.colour="black",background.circle.colour = "lightblue")


# Bu
resultat4Bu<- na.omit(spread((dataR2=dataR %>% 
  filter(!Date_courte == ("2021-01"))%>%
  filter(Site == ("Bu"))%>%
  filter(Micro %in% c("C1B1","C1B2","C1B3","C1B4","C1B5","C1B6","C1B7","C1B8"))%>%
  select(spp,Site,Date_courte,Micro) %>% 
  distinct() %>% 
  group_by(Site,Date_courte,Micro) %>% 
  summarize(S=n())),key=Micro,value=S)) 
resultat4Bu[is.na(resultat4Bu)]<-0

ggradar(resultat4Bu[,-1],grid.min = 0,grid.mid=7, grid.max =15,values.radar = c(0,7,15),group.colours = lcol2[c(2,4,6,8)],legend.title="Site Bu",gridline.max.linetype = 1,gridline.max.colour = "black",gridline.min.linetype = 1,gridline.min.colour="black",gridline.mid.linetype = 1,gridline.mid.colour="black",background.circle.colour = "lightblue")

# Fe
resultat4Fe<- na.omit(spread((dataR2=dataR %>%
  filter(!Date_courte == ("2021-01"))%>%
  filter(Site == ("Fe"))%>%
  filter(Micro %in% c("C1B1","C1B2","C1B3","C1B4","C1B5","C1B6","C1B7","C1B8"))%>%
  select(spp,Site,Date_courte,Micro) %>% 
  distinct() %>% 
  group_by(Site,Date_courte,Micro) %>% 
  summarize(S=n())),key=Micro,value=S)) 
resultat4Fe[is.na(resultat4Fe)]<-0

ggradar(resultat4Fe[,-1],grid.min = 0,grid.mid=7,grid.max =15,values.radar = c(0,7,15),group.colours = lcol2[c(1,4,5,6,7)], legend.title="Site Fe",gridline.max.linetype = 1,gridline.max.colour = "black",gridline.min.linetype = 1,gridline.min.colour="black",gridline.mid.linetype = 1,gridline.mid.colour="black",background.circle.colour = "lightblue")


# VB
resultat4VB<- na.omit(spread((dataR2=dataR %>%
  filter(!Date_courte == ("2021-01"))%>%
  filter(Site == ("VB"))%>%
  filter(Micro %in% c("C1B1","C1B2","C1B3","C1B4","C1B5","C1B6","C1B7","C1B8"))%>%
  select(spp,Site,Date_courte,Micro) %>% 
  distinct() %>% 
  group_by(Site,Date_courte,Micro) %>% 
  summarize(S=n())),key=Micro,value=S))
resultat4VB[is.na(resultat4VB)]<-0

ggradar(resultat4VB[,-1],grid.min = 0,grid.mid= 7,grid.max =15,values.radar = c(0,7,15),group.colours =lcol2[c(1:5,7:8)], legend.title="Site VB",gridline.max.linetype = 1,gridline.max.colour = "black",gridline.min.linetype = 1,gridline.min.colour="black",gridline.mid.linetype = 1,gridline.mid.colour="black",background.circle.colour = "lightblue")

##### Columns #####
par(mfrow=c(2,2))
#Bi
resultat3Bi<- na.omit(spread((dataR2=dataR %>% 
  filter(!Date_courte == ("2021-01"))%>%
  filter(Site == ("Bi"))%>%
  filter(Micro %in% c("C2P1","C2P2","C2P3","C2P4","C2P5","C2P6","C2P7","C2P8"))%>%
  select(spp,Site,Date_courte,Micro) %>% 
  distinct() %>% 
  group_by(Site,Date_courte,Micro) %>% 
  summarize(S=n())),key=Micro,value=S)) 
resultat3Bi[is.na(resultat3Bi)]<-0

ggradar(resultat3Bi[,-1],grid.min = 0,grid.max =10,grid.mid=5,values.radar = c(0,5,10),group.colours =lcol2[c(1,4,5,6,8)],legend.title="Site Bi",gridline.max.linetype = 1,gridline.max.colour = "black",gridline.min.linetype = 1,gridline.min.colour="black",gridline.mid.linetype = 1,gridline.mid.colour="black",background.circle.colour = "lightblue")


#Bu
resultat3Bu<- na.omit(spread((dataR2=dataR %>%
  filter(Site == ("Bu"))%>%
  filter(Micro %in% c("C2P1","C2P2","C2P3","C2P4","C2P5","C2P6","C2P7","C2P8"))%>%
  select(spp,Site,Date_courte,Micro) %>% 
  distinct() %>% 
  group_by(Site,Date_courte,Micro) %>% 
  summarize(S=n())),key=Micro,value=S))
resultat3Bu[is.na(resultat3Bu)]<-0

ggradar(resultat3Bu[,-1],grid.min = 0,grid.max =10,grid.mid=5,values.radar = c(0,5,10),group.colours =lcol2[c(1,2,4,5,8)],legend.title="Site Bu",gridline.max.linetype = 1,gridline.max.colour = "black",gridline.min.linetype = 1,gridline.min.colour="black",gridline.mid.linetype = 1,gridline.mid.colour="black",background.circle.colour = "lightblue")


#Fe
resultat3Fe<- na.omit(spread((dataR2=dataR %>% 
  filter(!Date_courte == ("2021-01"))%>%
  filter(Site == ("Fe"))%>%
  filter(Micro %in% c("C2P1","C2P2","C2P3","C2P4","C2P5","C2P6","C2P7","C2P8"))%>%
  select(spp,Site,Date_courte,Micro) %>% 
  distinct() %>% 
  group_by(Site,Date_courte,Micro) %>% 
  summarize(S=n())),key=Micro,value=S))
resultat3Fe[is.na(resultat3Fe)]<-0

ggradar(resultat3Fe[,-1],grid.min = 0,grid.max =10,grid.mid=5,values.radar = c(0,5,10),group.colours =lcol2[c(1,5,7)] ,legend.title="Site Fe",gridline.max.linetype = 1,gridline.max.colour = "black",gridline.min.linetype = 1,gridline.min.colour="black",gridline.mid.linetype = 1,gridline.mid.colour="black",background.circle.colour = "lightblue")


#VB
resultat3VB<- na.omit(spread((dataR2=dataR %>%
  filter(!Date_courte == ("2021-01"))%>%
  filter(Site == ("VB"))%>%
  filter(Micro %in% c("C2P1","C2P2","C2P3","C2P4","C2P5","C2P6","C2P7","C2P8"))%>%
  select(spp,Site,Date_courte,Micro) %>% 
  distinct() %>% 
  group_by(Site,Date_courte,Micro) %>% 
  summarize(S=n())),key=Micro,value=S))
resultat3VB[is.na(resultat3VB)]<-0

ggradar(resultat3VB[,-1],grid.min = 0,grid.max =10,grid.mid=5,values.radar = c(0,5,10),group.colours =lcol2[c(1:3,5,6,8)] ,legend.title="Site VB",gridline.max.linetype = 1,gridline.max.colour = "black",gridline.min.linetype = 1,gridline.min.colour="black",gridline.mid.linetype = 1,gridline.mid.colour="black",background.circle.colour = "lightblue")


```


# Utilisation des modèles
## Linear mixed model
```{r}
#Permet de montrer la significativité des valeurs selon des variables aléatoires

#permet de faire la moyenne du nombre de taxon dans chaque micro

dataR$saison<-dataR$Date_courte
dataR$saison[dataR$saison == "2021-04" | dataR$saison == "2022-04"] <- "printemps"
dataR$saison[dataR$saison == "2021-07" | dataR$saison == "2022-07"] <- "été"
dataR$saison[dataR$saison == "2021-10" | dataR$saison == "2021-11"| dataR$saison == "2022-11"] <- "automne"
dataR$saison[dataR$saison == "2022-01"] <- "hiver"

dataR2=dataR %>% ungroup %>% 
  select(spp,Site,Structure2,Micro,Date_courte,saison) %>% 
  distinct()%>% 
  group_by(Site,Structure2,Micro,Date_courte,saison) %>% 
  summarize(S=n()) %>%
  na.omit()

dataR3=dataR2 %>% 
  group_by(Site,Structure2,Date_courte,saison) %>% 
  summarize(S2 = mean(S))


plot(lm(S2~Site,data=dataR3))
mixed.lmer <- lmer(S2 ~ Site + (1|saison/Structure2), data = dataR3) #compare les données de richesse taxo avec les variables aléatoires qui sont Micro et date courte

mixed.lmer <- lmer(S2 ~ Site + (1|saison/Structure2), data = dataR3)

summary(mixed.lmer)
plot_model(mixed.lmer,show.values = T,show.p = T)#montre que par rapport à un site de réference (ici Bi), les autres sites sont différents. Ici Fetlar a plutot une diversité moindre que Bi mais est le plus proche. 
tab_model(mixed.lmer)

shapiro_test(lmer(S2 ~ Site + (1|saison/Structure2), data = dataR3))
leveneTest(S2~Site ,data=dataR3)
```

## Generalized linear model
```{r}
#Permet de montrer la significativité des valeurs selon des variables aléatoires

#ajoute une colonne de saison 
dataR$saison<-dataR$Date_courte
dataR$saison[dataR$saison == "2021-04" | dataR$saison == "2022-04"] <- "printemps"
dataR$saison[dataR$saison == "2021-07" | dataR$saison == "2022-07"] <- "été"
dataR$saison[dataR$saison == "2021-10" | dataR$saison == "2021-11"| dataR$saison == "2022-11"] <- "automne"
dataR$saison[dataR$saison == "2022-01"] <- "hiver"

dataR2=dataR %>% ungroup %>% 
  select(spp,Site,Structure2,Micro,Day_delta,saison) %>% 
  distinct()%>% 
  group_by(Site,Structure2,Micro,Day_delta,saison) %>% 
  summarize(S=n()) %>%
  na.omit()

dataR3=dataR2 %>% 
  group_by(Site,Structure2,Day_delta,saison) %>% 
  summarize(S2 = mean(S))
 
glm1<-glm(S2~as.numeric(Day_delta)+ Site,data=dataR3)
plot(glm1)
summary(glm1)
```

## Generalized Additive Models
```{r}
#Permet de montrer la significativité des valeurs selon des variables aléatoires

#ajoute une colonne de saison 
dataR$saison<-dataR$Date_courte
dataR$saison[dataR$saison == "2021-04" | dataR$saison == "2022-04"] <- "printemps"
dataR$saison[dataR$saison == "2021-07" | dataR$saison == "2022-07"] <- "été"
dataR$saison[dataR$saison == "2021-10" | dataR$saison == "2021-11"| dataR$saison == "2022-11"] <- "automne"
dataR$saison[dataR$saison == "2022-01"] <- "hiver"


#avec Richesse taxo
dataR2=dataR %>% ungroup %>% 
  select(spp,Site,Structure2,Micro,Day_delta,saison,Date_courte) %>% 
  filter(!Date_courte %in% c("2021-04",'2021-07',"2021-10","2021-11")) %>%
  # filter(Structure2 == "Disc") %>% 
  distinct()%>% 
  # mutate(Years=substr(Date_courte, start = 1, stop = 4)) %>%
  group_by(Site,Structure2,Micro,Day_delta,saison) %>% 
  summarize(S=n()) %>%
  na.omit()%>% 
  droplevels()

dataR3=dataR2 %>%
  group_by(Site,Structure2,Day_delta,saison) %>%
  summarize(S2 = mean(S))


## MCOV avec quadrat moyenné
dataR2=dataR %>% ungroup %>%
  select(spp,Site,Structure2,Micro,Day_delta,saison,Date_courte,Mcov,Quad2) %>%
  distinct()%>%
  mutate(Years=substr(Date_courte, start = 1, stop = 4)) %>%
  filter(Site =="Bi") %>%
  group_by(Site,Structure2,Day_delta,saison,Years,Mcov,Micro,Quad2) %>%
  # summarize(S=n()) %>%
  na.omit()%>%
  droplevels() 

dataR3=dataR2 %>%
  group_by(spp,Site,Structure2,Day_delta,saison,Micro) %>%
  summarize(Mcov2 = mean(Mcov,.by=c(spp,Micro,Day_delta,Quad2))) #moyenne du recouvrement des 2 quadrats/espèce/micro


dataR4=dataR3 %>%
    group_by(Site,Structure2,Day_delta,saison,Micro) %>%
summarize(Mcov3 = mean(Mcov2,.by=Micro))
    # dataR3$Mcov2= 100*dataR3$Mcov2/max(dataR3$Mcov2)
  # summarize(Mcov3 = sum(Mcov,.by=as.factor(Micro)))


#Richesse taxo
dataR3$Site<-as.factor(dataR3$Site)
dataR3$S2<-as.numeric(dataR3$S2)
# dataR3$S<-as.numeric(dataR3$S)
dataR3$saison<-as.factor(dataR3$saison)
# dataR3$Micro<-as.factor(dataR3$Micro)
dataR3$Day_delta<-as.numeric(dataR3$Day_delta)
# dataR3$Years<-as.factor(dataR3$Years)
str(dataR3)


#Mcov
dataR4$Site<-as.factor(dataR4$Site)
dataR4$Mcov3<-as.numeric(dataR4$Mcov3)
dataR4$saison<-as.factor(dataR4$saison)
dataR4$Micro<-as.factor(dataR4$Micro)
str(dataR4)


#test comparaison tous les paramètres
model1<-gam(S2~s(Day_delta)+Site,data=dataR3)
model11<-gam(S2~s(Day_delta)+Structure2,data=dataR3)
model111<-gam(S2~s(Day_delta)+saison,data=dataR3)
model1111<-gam(S2~s(Day_delta)+Site,data=dataR3)
model11111<-gam(S2~s(Day_delta)+Structure2+Site,data=dataR3)
model111111<-gam(S2~s(Day_delta)+s(Structure2,bs="re")+s(Site,bs="re")+s(saison,bs="re"),data=dataR3)
model11111111<-gam(Mcov2~s(Day_delta)+s(Structure2,bs='re')+s(Site,bs="re"),data=dataR3)
model111111111<-gam(Mcov3~s(Day_delta)+s(Structure2,bs='re')+s(Site,bs="re"),data=dataR4)
summary(model111111)

model2<-gam(S2~Site/Day_delta+s(Day_delta,bs="re"),data=dataR3)
model22<-gam(S2~Site/Day_delta+s(Day_delta,bs="re")+s(Structure2,bs='re'),data=dataR3)
model222<-gam(S2~Site/Day_delta+s(Day_delta,bs="re")+s(saison,bs="re"),data=dataR3)
model2222<-gam(S2~Site/Day_delta+s(Day_delta,bs="re")+s(Site,bs="re"),data=dataR3)
model22222<-gam(S2~Site/Day_delta+s(Day_delta,bs="re")+s(saison,bs="re")+s(Site,bs="re"),data=dataR3)
model222222<-gam(S2~Site/Day_delta+s(Day_delta,bs="re")+s(saison,bs="re")+s(Structure2,bs='re'),data=dataR3)
model2222222<-gam(S2~Site/Day_delta+s(Day_delta,bs="re")+s(Structure2,bs='re')+s(Site,bs="re")+s(saison,bs="re"),data=dataR3)


AIC(model1,model11,model111,model1111,model11111,model111111)
AIC(model2,model22,model222,model2222,model22222,model222222,model2222222)

par(mfrow= c(1,1))
plot(model11111111,shift=mean(dataR3$S2),residuals=T,cex=1,pch=16,col="blue",shade=T,shade.col='grey')
plot(model111111111,shift=mean(dataR3$Mcov2),residuals=T,cex=0.7,pch=16,col="blue",shade=T,shade.col='grey')


#test comparaison tous les paramètres
library(MuMIn)
options(na.action = "na.fail")
fm1<-gam(S2~s(Day_delta)+s(Structure2,bs="re")+s(Site,bs="re")+s(saison,bs="re"),data=dataR3)
ms1<-dredge(fm1)


#plot de la gam
plot(model111111,shift=mean(dataR3$S2),residuals=T,cex=0.7,pch=16,col="blue",shade=T,shade.col='grey')
ggplot(data = dataR3, mapping = aes(x = Day_delta, y = S2)) +
  geom_point(size = 0.7, alpha = 0.7) +
  geom_smooth(method="gam", formula= y~s(x))+
  theme_bw()

plot_smooths(model=model111111, series=Day_delta,comparison=Site)+theme_bw() #permet de mettre les gam selon les sites


#calcul correlation day_delta et years
cor(dataR3$Day_delta,dataR3$Years)

#### Conditions d'applications
par(mfrow = c(2, 2))
gam.check(model111111)


#Homoscédasticité
leveneTest(lmmodel)#si supérieur à alpha alors homoscedastique
plot(model1$residuals~model1$fitted.values)

lmmodel<-lm(S2~Site/Day_delta+saison,data=dataR3)
lmmodel<-gam(S2~Site,data=dataR3)
# ncvTest(lmmodel) #que avec lm

#normalité des valeurs
shapiro_test(lmmodel$residuals) #si supérieur à alpha alors hypothèse de normalité acceptée
shapiro_test(dataR3$S2)  
hist(dataR3$S2)
qqnorm(lmmodel$residuals)
qqline(lmmodel$residuals)
dataR3 %>% shapiro_test(S2)

```


# Vitesse de colonisation 
```{r}
# Quelle est la vitesse de colonisation de chaque site et comment évoluent-t-elles ?

# à utiliser avec les les lignes de dataR$nummois d'avant
seq<-c(0,0)
seq2<-c(0,0,0)

###Bizeux
dataR21=dataR %>% ungroup %>% 
  select(spp,Site,Structure2,Micro,Day_delta) %>%
  filter(Site == "Bi") %>% 
  distinct()%>%
  group_by(Site,Structure2,Micro,Day_delta) %>%
  summarize(S=n()) %>%
  na.omit()

dataR310=dataR21 %>%
  group_by(Site,Day_delta) %>%
  summarize(S2 = mean(S))

dataR31<-dataR310

dataR3Bi<-dataR31$Site[-1]
dataR31$Day_delta<-as.numeric(dataR31$Day_delta)
dataR31$S2<-as.numeric(dataR31$S2)
dataR31<-dataR31[,-1]
dataR31<-rbind(seq,dataR31)
dataR311<-dataR31[order(dataR31$Day_delta),]
dataR3<-dataR311[-1,]-dataR311[-nrow(dataR311),]
dataR3$SparT<-dataR3$S/dataR3$Day_delta
dataR31<-rbind(seq,dataR3[,-2])


### Buharats
dataR22=dataR %>% ungroup %>% 
  select(spp,Site,Structure2,Micro,Day_delta) %>%
  filter(Site == "Bu") %>% 
  distinct()%>%
  group_by(Site,Structure2,Micro,Day_delta) %>%
  summarize(S=n()) %>%
  na.omit()

dataR320=dataR22 %>%
  group_by(Site,Day_delta) %>%
  summarize(S2 = mean(S))

dataR32<-dataR320

dataR3Bu<-dataR32$Site[-1]
dataR32$Day_delta<-as.numeric(dataR32$Day_delta)
dataR32$S2<-as.numeric(dataR32$S2)
dataR32<-dataR32[,-1]
dataR32<-rbind(seq,dataR32)
dataR311<-dataR32[order(dataR32$Day_delta),]
dataR3<-dataR311[-1,]-dataR311[-nrow(dataR311),]
dataR3$SparT<-dataR3$S/dataR3$Day_delta
dataR32<-rbind(seq,dataR3[,-2])

### Fetlar
dataR23=dataR %>% ungroup %>% 
  select(spp,Site,Structure2,Micro,Day_delta) %>%
  filter(Site == "Fe") %>% 
  distinct()%>%
  group_by(Site,Structure2,Micro,Day_delta) %>%
  summarize(S=n()) %>%
  na.omit()

dataR330=dataR23 %>%
  group_by(Site,Day_delta) %>%
  summarize(S2 = mean(S))

dataR33<-dataR330

dataR3Fe<-dataR33$Site[-1]
dataR33$Day_delta<-as.numeric(dataR33$Day_delta)
dataR33$S2<-as.numeric(dataR33$S2)
dataR33<-dataR33[,-1]
dataR33<-rbind(seq,dataR33)
dataR311<-dataR33[order(dataR33$Day_delta),]
dataR3<-dataR311[-1,]-dataR311[-nrow(dataR311),]
dataR3$SparT<-dataR3$S/dataR3$Day_delta
dataR33<-rbind(seq,dataR3[,-2])

### Vieux Bancs
dataR24=dataR %>% ungroup %>% 
  select(spp,Site,Structure2,Micro,Day_delta) %>%
  filter(Site == "VB") %>% 
  distinct()%>%
  group_by(Site,Structure2,Micro,Day_delta) %>%
  summarize(S=n()) %>%
  na.omit()

dataR340=dataR24 %>%
  group_by(Site,Day_delta) %>%
  summarize(S2 = mean(S))

dataR34<-dataR340

dataR3VB<-dataR34$Site[-1]
dataR34$Day_delta<-as.numeric(dataR34$Day_delta)
dataR34$S2<-as.numeric(dataR34$S2)
dataR34<-dataR34[,-1]
dataR34<-rbind(seq,dataR34)
dataR311<-dataR34[order(dataR34$Day_delta),]
dataR3<-dataR311[-1,]-dataR311[-nrow(dataR311),]
dataR3$SparT<-dataR3$S/dataR3$Day_delta
dataR34<-rbind(seq,dataR3[,-2])


dataRjour1<-c(0,dataR310$Day_delta)
dataRjour2<-c(0,dataR320$Day_delta)
dataRjour3<-c(0,dataR330$Day_delta)
dataRjour4<-c(0,dataR340$Day_delta)


# dataR2total<-rbind(dataR2Bi,dataR2Bu,dataR2Fe,dataR2VB)
# dataR7<-cbind(dataR2$Site,dataR3$SparT,dataR4$SparT,dataR5$SparT,dataR6$SparT)

plot(dataR31$SparT~dataRjour1,col="red",xlim=c(0,800),ylim=c(-0.07,0.05),pch=19,xlab="Nombre de jours",ylab="Nombre moyen d'espèces  colonisant par jour")
par(new=T)
plot(dataR32$SparT~dataRjour2,col="blue",xlim=c(0,800),ylim=c(-0.07,0.05),pch=19,xlab="",ylab="")
par(new=T)
plot(dataR33$SparT~dataRjour3,col="green",xlim=c(0,800),ylim=c(-0.07,0.05),pch=19,xlab="",ylab="")
par(new=T)
plot(dataR34$SparT~dataRjour4,col="black",xlim=c(0,800),ylim=c(-0.07,0.05),pch=19,xlab="",ylab="")
lines(dataR31$SparT~dataRjour1,col="red",xlim=c(0,800),ylim=c(-0.07,0.05),pch=19,xlab="",ylab="")
lines(dataR32$SparT~dataRjour2,col="blue",xlim=c(0,800),ylim=c(-0.07,0.05),pch=19,xlab="",ylab="")
lines(dataR33$SparT~dataRjour3,col="green",xlim=c(0,800),ylim=c(-0.07,0.05),pch=19,xlab="",ylab="")
lines(dataR34$SparT~dataRjour4,col="black",xlim=c(0,800),ylim=c(-0.07,0.05),pch=19,xlab="",ylab="")
legend(x = "bottomright", legend = c("Bi","Bu","Fe","VB"),lty = 1, col = c("red","blue","green","black"),lwd = 2)


# plot(S~nummois,data=dataR2)
# lm1<-lm(S~nummois,data=dataR2)
# 
# model1<-nls(S~(a*nummois)/(b+nummois),start=list(b=10,a=120),data=dataR2)

```

# Représentation spatial
## Matrice de distance
```{r}
# Permet de calculer la distance entre le recouvrement de chaque espèce et le taux de recouvrement

levels(factor(dataR$Site))
# test=data_PQ_light %>% filter(Site=='DSC')


# data_comp2=data_PQ_light %>% ungroup %>% 
#   select(spp,Cov,Site,Micro,Date_courte,Structure2,Strcut_groups, Quad2) %>% 
#   filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte')) %>%
# <<<<<<< HEAD
#   filter(!Structure2 %in% c('Dome','Holes','Upper_slots','Inner_slots')) %>% 
#   group_by(spp,Site,Micro,Date_courte,Structure2) %>% 
# =======
#   filter(!Structure2 %in% c('Dome','Upper_slots' )) %>% 
#     filter(!Site %in% c('Fe','DSC' )) %>% 
#   mutate(Sample=paste0(Site,'_',Date_courte,'_',
#                        Micro,'_',Quad2)) %>% 
#   group_by(Sample,Site,spp, Micro,Structure2,Strcut_groups, Date_courte) %>% 
#   dplyr::summarize(Mcov=mean(Cov)) %>% 
# 
#   group_by(Sample,Site,Micro,Date_courte,Structure2) %>% 
# >>>>>>> d7a3076aa8c86cd4609b46ec0f575f800cd1d573
#   distinct() %>% drop_na() %>% 
#     spread(spp,Mcov) %>% ungroup() %>% 
#       mutate(across(everything(.), ~replace_na(., 0))) 

#ajoute une colonne de saison 
dataR$saison<-dataR$Date_courte
dataR$saison[dataR$saison == "2021-04" | dataR$saison == "2022-04"] <- "printemps"
dataR$saison[dataR$saison == "2021-07" | dataR$saison == "2022-07"] <- "été"
dataR$saison[dataR$saison == "2021-10" | dataR$saison == "2021-11"| dataR$saison == "2022-11"] <- "automne"
dataR$saison[dataR$saison == "2022-01"] <- "hiver"

data_comp2=dataR %>% ungroup %>% 
  select(spp,Mcov,Site,Micro,Date_courte,Structure2,saison,Quad2,Day_delta) %>% 
  mutate(Years=substr(Date_courte, start = 1, stop = 4)) %>%
  group_by(spp,Site,Micro,Date_courte,Structure2,saison,Years,Day_delta) %>% 
  distinct() %>% drop_na() %>% 
  summarize(Mcov2 = mean(Mcov,.by=c(spp,Micro,Day_delta,Quad2))) %>%
  spread(spp,Mcov2) %>% ungroup() %>% 
  mutate(across(everything(.), ~replace_na(., 0))) 

# data_comp2$nouvelle<-ifelse(data_comp2$Structure2 == "Pillars" | data_comp2$Structure2 == "Columns", "Pillars", "Autres")
# data_comp2$nouvelle<-ifelse(data_comp2$Structure2 == "Pillars", "Pillars", "Autres")

data_comp2$Site<-as.factor(data_comp2$Site)
data_comp2$Micro<-as.factor(data_comp2$Micro)
data_comp2$Date_courte<-as.factor(data_comp2$Date_courte)
data_comp2$Day_delta<-as.factor(data_comp2$Day_delta)
# data_comp2$nouvelle<-as.factor(data_comp2$nouvelle)
data_comp2$Years<-as.factor(data_comp2$Years)

# test=data_comp2 %>% filter(Site == 'VB',
                          # Date_courte=='2021-07' )
# data_comp2=data_comp2[rowSums(data_comp2)>0,]

# Comp_mat=data_comp2 %>% select(-c(Site,Sample,Micro,Structure2,Strcut_groups,Date_courte)) %>% as.matrix() 
# Meta_data=data_comp2 %>% select(Site,Sample,Micro,Structure2,Strcut_groups,Date_courte)

Comp_mat=data_comp2 %>% select(-c(Site,Micro,Structure2,Date_courte,saison,Years,Day_delta)) %>% as.matrix() #sans meta données
Meta_data=data_comp2 %>% select(Site,Micro,Structure2,Date_courte,saison,Years,Day_delta) #meta données

# Comp_mat=data_comp2 %>% select(-c(Site,Micro,Structure2,Date_courte,nouvelle,saison)) %>% as.matrix() #sans meta données
# Meta_data=data_comp2 %>% select(Site,Micro,Structure2,Date_courte,nouvelle,saison) #meta données


distdataR<-vegdist(Comp_mat, method='bray') #library vegan - distance de Bray-Curtis, considéré face aux distances euclidiennes comme plus efficace pour les données écologiques


```

##  PCoA
```{r}
# Permet de représenter les données dans l'espace et voir les paramètres expliquant le plus la variance

pcoa_tot_SS<- cmdscale(d = as.matrix(distdataR),k=10, eig = T) 
x=pcoa_tot_SS$points[,1]
y=pcoa_tot_SS$points[,2]

plot(x,y) 

PCOA_df=data.frame(x=pcoa_tot_SS$points[,1],y=pcoa_tot_SS$points[,2],
                   Structure=Meta_data$Structure2,
                   Site=Meta_data$Site,
                   Date=Meta_data$Date_courte,
                   Saison=Meta_data$saison,
                   Years=Meta_data$Years
                   # Structure3=Meta_data$nouvelle
                   )

ggplot(data=PCOA_df,aes(x,y, col=Years))+ # <- Ici on explore avec col les variable qui explique le + l'explosion du nuage de points
  # geom_point(aes(col=Site), size=1, alpha=.6)+
  geom_point()+
  labs(x="Axe 1 (temporalité)",y="Axe 2")+
  geom_hline(yintercept=0)+
  geom_vline(xintercept=0)+
  theme_bw()
  # geom_mark_ellipse(aes(fill=Structure,group=Structure))

# apport de la variabilité selon le nombre d'axe
summaryPCOA<-data.frame(
  EIG= pcoa_tot_SS$eig,
  PCTVAR=100*pcoa_tot_SS$eig/sum(pcoa_tot_SS$eig),
  CUMPCTVAR = cumsum(100*pcoa_tot_SS$eig/sum(pcoa_tot_SS$eig)))

plot(summaryPCOA$PCTVAR[1:30],ylim=c(0,25),
        xlab="Composantes",ylab="Pourcentage d'inertie (explication de la variance)")



### Explication de la variance par les variables
#test avec factominer (fonctionne mais les axes n'expliquent pas la même variance que l'ACoP plus haut)
res.pca<-PCOA_df[,c(1:2)]
res.pca<-PCA(x,y)
res.pca<-PCA(Comp_mat,ncp=6)
res.pca2<-plot(res.pca)

res_va<-dimdesc(res.pca2,axes=c(1,2))#permet d'avoir la corrélation
res_va<-dimdesc(res.pca)

res_va_dim1<-cbind(rep("Dim1",times=6),head(res_va$Dim.1$quanti))
res_va_dim2<-cbind(rep("Dim2",times=6),head(res_va$Dim.2$quanti))
res_va_dim3<-cbind(rep("Dim3",times=6),head(res_va$Dim.3$quanti))
res_va_spp<-as.data.frame(rbind(res_va_dim1,res_va_dim2,res_va_dim3))

res_va$Dim.1$quanti[,1]
```

## Permanova
```{r}
# Permet de voir s'il y a possibilité de regrouper les structures

data_comp2=dataR %>% ungroup %>% 
  select(spp,Mcov,Site,Micro,Day_delta,Structure2) %>% 
  group_by(spp,Site,Micro,Day_delta,Structure2) %>% 
  distinct() %>% drop_na() %>% 
  spread(spp,Mcov) %>% ungroup() %>% 
  mutate(across(everything(.), ~replace_na(., 0))) 

Comp_mat=data_comp2 %>% select(-c(Site,Structure2,Date_courte,Micro)) %>% as.matrix() #sans meta données

distdataR<-vegdist(Comp_mat, method='bray')

adonis2(distdataR~Structure2,data=data_comp2,permutations=999)


# Permet de voir si les microhabitats possèdent une richesse taxo équivalente et donc qu'ils peuvent etre regroupés

data_comp2=dataR %>% ungroup %>% 
  filter(Site == 'VB') %>%
  filter(Structure2 == 'Inner_slots') %>%
  select(spp,Mcov,Site,Micro,Day_delta,Structure2) %>% 
  group_by(spp,Site,Micro,Day_delta,Structure2) %>% 
  distinct() %>% drop_na() %>% 
  spread(spp,Mcov) %>% ungroup() %>% 
  mutate(across(everything(.), ~replace_na(., 0))) 

Comp_mat=data_comp2 %>% select(-c(Site,Structure2,Day_delta,Micro)) #sans meta données

distdataR<-vegdist(Comp_mat, method='bray')

adonis2(distdataR~Micro,data=data_comp2,permutations=999)



# Pair wise permanova 
groupe<-data_comp2$Structure2
groupe<-data_comp2$Site
groupe<-data_comp2$Day_delta
groupe<-data_comp2$Micro

pairwise.adonis(distdataR,groupe,perm=999,sim.method = 'bray',p.adjust.m='bonferroni')
adonis3<-permanova_pairwise(distdataR,groupe,permutations=999,method='bray',padj="bonferroni")

pv<-adonis3$p.adj
pv<-c(0,)
Site<-adonis3$pairs
Site<-c("Colonnes","Disques","Dome","Pillars")
table(pv,Site)
Sitepv<-cbind(site,pv)

heatmap(as.matrix(as.numeric(adonis3$p.adj)))
site<-c("Disques","Colonnes","Dome","Pilliers")

Sitepv<-cbind(site,pv)

```

## ANOSIM
```{r}
#Similaire à une ANOVA mais utilise une matrice de dissimilarité en entrée de data

data_comp2=dataR %>% ungroup %>% 
  select(spp,Mcov,Site,Micro,Structure2,Date_courte) %>% 
  filter(Site == "Bu") %>% 
  filter(Date_courte %in% c("2021-11","2022-11")) %>% 
  group_by(spp,Site,Micro,Structure2) %>% 
  distinct() %>% drop_na() %>% 
  spread(spp,Mcov) %>% ungroup() %>% 
  mutate(across(everything(.), ~replace_na(., 0))) 

datano=data_comp2[,-c(1:4)] %>% as.matrix()

ano=anosim(datano,droplevels(data_comp2$Structure2),distance="bray",permutations=999)
ano 
plot(ano,xlab="Structures",ylab="Rang de distance entre les échantillons")
```


## Classification hiérarchique
```{r}
dataR$saison<-dataR$Date_courte
dataR$saison[dataR$saison == "2021-04" | dataR$saison == "2022-04"] <- "printemps"
dataR$saison[dataR$saison == "2021-07" | dataR$saison == "2022-07"] <- "été"
dataR$saison[dataR$saison == "2021-10" | dataR$saison == "2021-11"| dataR$saison == "2022-11"] <- "automne"
dataR$saison[dataR$saison == "2022-01"] <- "hiver"

data_comp2=dataR %>% ungroup %>% 
  select(spp,Mcov,Site,Micro,Date_courte,Structure2,saison) %>% 
  group_by(spp,Site,Micro,Date_courte,Structure2,saison) %>% 
  distinct() %>% drop_na() %>% 
  spread(spp,Mcov) %>% ungroup() %>% 
  mutate(across(everything(.), ~replace_na(., 0))) 

data_comp2$Site<-as.factor(data_comp2$Site)
data_comp2$Micro<-as.factor(data_comp2$Micro)
data_comp2$Date_courte<-as.factor(data_comp2$Date_courte)

Comp_mat=data_comp2 %>% select(-c(Site,Micro,Structure2,Date_courte,saison)) %>% as.matrix() #sans meta données
Meta_data=data_comp2 %>% select(Site,Micro,Structure2,Date_courte,saison) #meta données

distdataR<-vegdist(Comp_mat, method='bray')

arbre <- hclust(distdataR, method = "ward.D2")
plot(arbre, labels = FALSE, main = "Dendrogramme")
ggdendrogram(arbre,labels=FALSE)

```

# Courbe d'accumulation
## Méthode 1 (intrapolation)
```{r}
#Permet de savoir le nombre de taxon retrouvé selon l'effort d'inventaire
# Courbe d'accumulation package vegan (seulement intrapolation)

data_comp2=data_PQ_light %>% ungroup %>% 
  select(spp,Mcov,Site,Micro,Date_courte,Structure2) %>% 
  filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte'),) %>%
  filter(Structure2 == "Pillars") %>% 
  filter(Site == "Bi")%>%
    filter(Date_courte %in% c("2022-07")) %>% 

  # filter(Date_courte %in% c("2022-07","2022-04","2022-11","2022-01"))%>%
  group_by(spp,Site,Micro,Date_courte,Structure2) %>% 
  distinct() %>% drop_na() %>% 
    spread(spp,Mcov) %>% ungroup() %>% 
      mutate(across(everything(.), ~replace_na(., 0))) 

Comp_mat2=data_comp2 %>% ungroup() %>%  select(-c(Site,Micro,Structure2,Date_courte)) %>% as.matrix() 

data_comp3=data_PQ_light %>% ungroup %>% 
  select(spp,Mcov,Site,Micro,Date_courte,Structure2) %>% 
  filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte')) %>%
  filter(Structure2 == "Pillars") %>% 
  filter(Site == "Bu")%>%
  # filter(Date_courte %in% c("2022-07","2022-04","2022-11","2022-01"))%>%
  group_by(spp,Site,Micro,Date_courte,Structure2) %>% 
  distinct() %>% drop_na() %>% 
    spread(spp,Mcov) %>% ungroup() %>% 
      mutate(across(everything(.), ~replace_na(., 0))) 

Comp_mat3=data_comp3 %>% select(-c(Site,Micro,Structure2,Date_courte)) %>% as.matrix() 


data_comp4=data_PQ_light %>% ungroup %>% 
  select(spp,Mcov,Site,Micro,Date_courte,Structure2) %>% 
  filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte')) %>%
  filter(Structure2 == "Pillars") %>% 
  filter(Site == "VB")%>%
  filter(Date_courte %in% c("2022-07","2022-04","2022-11","2022-01"))%>%
  group_by(spp,Site,Micro,Date_courte,Structure2) %>% 
  distinct() %>% drop_na() %>% 
    spread(spp,Mcov) %>% ungroup() %>% 
      mutate(across(everything(.), ~replace_na(., 0))) 

Comp_mat4=data_comp4 %>% select(-c(Site,Micro,Structure2,Date_courte)) %>% as.matrix() 


data_comp5=data_PQ_light %>% ungroup %>% 
  select(spp,Mcov,Site,Micro,Date_courte,Structure2) %>% 
  filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte')) %>%
  filter(Structure2 == "Pillars") %>% 
  filter(Site == "Fe")%>%
  filter(Date_courte %in% c("2022-07","2022-04","2022-11","2022-01"))%>%
  group_by(spp,Site,Micro,Date_courte,Structure2) %>% 
  distinct() %>% drop_na() %>% 
    spread(spp,Mcov) %>% ungroup() %>% 
      mutate(across(everything(.), ~replace_na(., 0))) 

Comp_mat5=data_comp5 %>% select(-c(Site,Micro,Structure2,Date_courte)) %>% as.matrix() 


spBi<-specaccum(Comp_mat2)
spBu<-specaccum(Comp_mat3)
spVB<-specaccum(Comp_mat4)
spFe<-specaccum(Comp_mat5)


plot(spBi,col="blue",ci.type="poly",ci.lty=0,ci.col="lightblue",ylim=c(0,30),xlim=c(0,12),ylab="Nombre d'espèces",xlab="Nombre de mesures",main="Courbe accumulative taxons 2022 pilliers/Site")
par(new=T)
plot(spBi2,col="darkgreen",ci.type="poly",ci.lty=0,ci.col="lightgreen",ylim=c(0,30),xlim=c(0,12),ylab="",xlab="")
par(new=T)
plot(spBi3,col="orange",ci.type="poly",ci.lty=0,ci.col="lightyellow",ylim=c(0,30),xlim=c(0,12),ylab="",xlab="")
par(new=T)
plot(spBi4,col="red",ci.type="poly",ci.lty=0,ci.col="#FCBBA1",ylim=c(0,30),xlim=c(0,12),ylab="",xlab="")
par(new=T)
plot(spBi5,col="black",ci.type="poly",ci.lty=0,ci.col="grey",ylim=c(0,30),xlim=c(0,12),ylab="",xlab="")

legend(x = "bottomright", legend = c("Bi","VB","Fe","Bu"),lty = 1, col = c("blue","darkgreen","orange","red"),lwd = 2)

#permet de voir les indices tels que chao/ bootstrap,....
spBi<-specaccum(Comp_mat2)
pool<-specpool(Comp_mat5)
poolaccum(Comp_mat5,permutation=100)
plot(poolaccum(Comp_mat3,permutation=100))

estimateR(as.integer(Comp_mat2))
estimateR(as.integer(Comp_mat3))
estimateR(as.integer(Comp_mat4))
estimateR(as.integer(Comp_mat5))

```

## Méthode 2 (intra et extrapolation)

```{r}
#Création d'une matrice d'incidence

# On réorganise le df de base
# Ajout d'une variable qui combine la date et la structure

### Disques
data_comp1=data_PQ_light %>% ungroup %>% 
  select(spp,Date_courte,Site,Structure2, Code_struct) %>% 
   filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte','None')) %>%
  mutate(date_st=paste0(Date_courte,'_',Code_struct)) %>%  # 
  filter(Structure2 == ("Disc")) %>%
  mutate(P=1) %>% 
    select(-c(Date_courte,Code_struct)) %>% 
  distinct() %>% group_by(Site) %>% 
  group_split()

# On créait une fonction pour nettoyer l'intérieur de la liste
fun_clean=function(x){
  x %>% spread(date_st,P) %>% 
    select(-c(spp,Site,Structure2)) %>% 
      mutate(across(everything(.), ~replace_na(., 0))) %>% 
  as.data.frame()}

# Convertion de split df en list
comp_list=as.list(data_comp1)

# Application de la fonction + names
comp_list_clean=lapply(comp_list, fun_clean)
names(comp_list_clean)<-c('Bi','Bu','Fe','Vb')

# Fonction
out.raw <- iNEXT(comp_list_clean,q=0,
                 datatype="incidence_raw",
                 endpoint=80)
plot(out.raw)
# ggiNEXT(out.raw)

ChaoRichness(comp_list_clean,datatype = 'incidence_raw')

# Ici tu les données concernant l'estimation de la rich. totale
Rar_disc_df=as.data.frame(out.raw$AsyEst)

poolaccum(comp_list_clean)



### Colonnes
data_comp1=data_PQ_light %>% ungroup %>% 
  select(spp,Date_courte,Site,Structure2, Code_struct) %>% 
   filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte','None')) %>%
  mutate(date_st=paste0(Date_courte,'_',Code_struct)) %>%  # 
  filter(Structure2 == ("Columns")) %>% 
  mutate(P=1) %>% 
    select(-c(Date_courte,Code_struct)) %>% 
  distinct() %>% group_by(Site) %>% 
  group_split()

# On créait une fonction pour nettoyer l'intérieur de la liste
fun_clean=function(x){
  x %>% spread(date_st,P) %>% 
    select(-c(spp,Site,Structure2)) %>% 
      mutate(across(everything(.), ~replace_na(., 0))) %>% 
  as.data.frame()}

# Convertion de split df en list
comp_list=as.list(data_comp1)

# Application de la fonction + names
comp_list_clean=lapply(comp_list, fun_clean)
names(comp_list_clean)<-c('Bi','Bu','Fe','Vb')

# Fonction
out.raw <- iNEXT(comp_list_clean,q=0,
                 datatype="incidence_raw",
                 endpoint=80)
plot(out.raw)
# Ici tu les données concernant l'estimation de la rich. totale
Rar_disc_df=as.data.frame(out.raw$AsyEst)





### Piliers
data_comp1=data_PQ_light %>% ungroup %>% 
  select(spp,Date_courte,Site,Structure2, Code_struct) %>% 
   filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte','None')) %>%
  mutate(date_st=paste0(Date_courte,'_',Code_struct)) %>%  # 
  filter(Structure2 == ("Pillars")) %>% 
  mutate(P=1) %>% 
    select(-c(Date_courte,Code_struct)) %>% 
  distinct() %>% group_by(Site) %>% 
  group_split()

# On créait une fonction pour nettoyer l'intérieur de la liste
fun_clean=function(x){
  x %>% spread(date_st,P) %>% 
    select(-c(spp,Site,Structure2)) %>% 
      mutate(across(everything(.), ~replace_na(., 0))) %>% 
  as.data.frame()}

# Convertion de split df en list
comp_list=as.list(data_comp1)

# Application de la fonction + names
comp_list_clean=lapply(comp_list, fun_clean)
names(comp_list_clean)<-c('Bi','Bu','Fe','Vb')

# Fonction
out.raw <- iNEXT(comp_list_clean,q=0,
                 datatype="incidence_raw",
                 endpoint=80)
plot(out.raw)

# Ici tu les données concernant l'estimation de la rich. totale
Rar_disc_df=as.data.frame(out.raw$AsyEst)


### Colonnes
data_comp1=data_PQ_light %>% ungroup %>% 
  select(spp,Date_courte,Site,Structure2, Code_struct) %>% 
   filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte','None')) %>%
  mutate(date_st=paste0(Date_courte,'_',Code_struct)) %>%  # 
  filter(Structure2 == ("Inner_slots")) %>% 
  mutate(P=1) %>% 
    select(-c(Date_courte,Code_struct)) %>% 
  distinct() %>% group_by(Site) %>% 
  group_split()

# On créait une fonction pour nettoyer l'intérieur de la liste
fun_clean=function(x){
  x %>% spread(date_st,P) %>% 
    select(-c(spp,Site,Structure2)) %>% 
      mutate(across(everything(.), ~replace_na(., 0))) %>% 
  as.data.frame()}

# Convertion de split df en list
comp_list=as.list(data_comp1)

# Application de la fonction + names
comp_list_clean=lapply(comp_list, fun_clean)
names(comp_list_clean)<-c('Bi','Bu','Fe','Vb')

# Fonction
out.raw <- iNEXT(comp_list_clean,q=0,
                 datatype="incidence_raw",
                 endpoint=80)
plot(out.raw)
# Ici tu les données concernant l'estimation de la rich. totale
Rar_disc_df=as.data.frame(out.raw$AsyEst)





### Toutes les structures 
data_comp1=data_PQ_light %>% ungroup %>% 
  select(spp,Date_courte,Site,Structure2, Code_struct) %>% 
   filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte','None')) %>%
  mutate(date_st=paste0(Date_courte,'_',Code_struct)) %>%  
   filter(Structure2 %in% c("Disc","Pillars","Columns","Inner_slots")) %>% 
  mutate(P=1) %>% 
    select(-c(Date_courte,Code_struct)) %>% 
  distinct() %>% group_by(Site) %>% 
  group_split()


# On créait une fonction pour nettoyer l'intérieur de la liste
fun_clean=function(x){
  x%>% spread(date_st,P) %>% 
    distinct(spp,.keep_all = TRUE) %>% #ajout de cette fonction permettant de ne pas additionner les taxons en fonction des structures
    select(-c(spp,Site,Structure2)) %>% 
      mutate(across(everything(.), ~replace_na(., 0))) %>% 
  as.data.frame()}

# Convertion de split df en list
comp_list=as.list(data_comp1)

# Application de la fonction + names
comp_list_clean=lapply(comp_list, fun_clean)
names(comp_list_clean)<-c('Bi','Bu','Fe','Vb')

# Fonction
out.raw <- iNEXT(comp_list_clean,q=0,
                 datatype="incidence_raw",
                 endpoint=250)
plot(out.raw)


# Ici tu les données concernant l'estimation de la rich. totale
Rar_disc_df=as.data.frame(out.raw$AsyEst)

specpool(as.numeric(comp_list_clean))


```



# Test différence échantillonage
```{r}

dataR2=dataR %>% ungroup %>%
  select(Site,Day_delta,Structure2) %>% 
  distinct()%>% 
  group_by(Site,Day_delta,Structure2) %>% 
  summarize(S3=sum(n(Site)),.by=Structure2) %>%
  na.omit()


seqdate<-c('153','244','367','428','518','609','732')
Bid<-as.numeric(rep(8,times=7))
Bic<-c(8,7,8,8,8,7,8)
Bip<-rep(3,times=7)
Bis<-c(8,8,8,7,8,8,8)
Birep<-rep("Bi",times=7)
Bidata<-as.data.frame(cbind(Birep,seqdate,Bid,Bic,Bip,Bis))
colnames(Bidata)<-c("Site","Nbjourimmer","Disques","Colonnes","Pilliers","Slots")
Bidata$Nbjourimmer<-as.factor(Bidata$Nbjourimmer)
Bidata$Disques<-as.numeric(Bidata$Disques)
Bidata$Colonnes<-as.numeric(Bidata$Colonnes)
Bidata$Pilliers<-as.numeric(Bidata$Pilliers)
Bidata$Slots<-as.numeric(Bidata$Slots)
Bidata2<-spread(Bidata,key=Birep,value=Bid)
ggplot(Bidata,aes(fill=))

Bud<-c(7,8,8,5,8,"",8)
Buc<-c(8,7,8,8,4,"",8)
Bup<-c(3,3,3,3,3,"",3)
Bus<-c(7,8,8,7,8,"",7)
Burep<-rep("Bu",times=7)
Budata<-cbind(Burep,seqdate,Bud,Buc,Bup,Bus)

Fed<-c(8,"",8,8,8,8,"")
Fec<-c(8,"",5,8,6,8,"")
Fep<-c(3,"",3,3,0,8,"")
Fes<-c(8,"",8,8,8,8,"")
Ferep<-rep("Bu",times=7)
Fedata<-cbind(Ferep,seqdate,Fed,Fec,Fep,Fes)

VBd<-c(8,8,8,8,7,8,8)
VBc<-c(8,8,"",8,7,8,8)
VBp<-c(3,3,"",3,3,3,3)
VBs<-c(6,7,7,8,7,8,8)
VBrep<-rep("VB",times=7)
VBdata<-cbind(VBrep,seqdate,VBd,VBc,VBp,VBs)

datanumber<-as.data.frame(rbind(Bidata,Budata,Fedata,VBdata))
datanumber2<-as.data.frame(cbind(Bidata,Budata,Fedata,VBdata))

colnames(datanumber)<-c("Site","Date","Disques","Colonnes","Pilliers","Slots")
datanumber$Date<-as.factor(datanumber$Date)
datanumber$Site<-as.factor(datanumber$Site)
datanumber$Disques<-as.numeric(datanumber$Disques)
datanumber$Colonnes<-as.numeric(datanumber$Colonnes)
datanumber$Pilliers<-as.numeric(datanumber$Pilliers)
datanumber$Slots<-as.numeric(datanumber$Slots)

plot(datanumber$Date,datanumber$Disques)

ggplot(datanumber, aes(Date,Colonnes, fill=Site))+ # Avec "fill" ou "col" du peut ajout une séparation de tes données par facteur (ici le site)
  xlab("Structure")+
  ylab("Richesse taxonomique")+
  # geom_jitter(alpha=.3)+  # On ajoute les points (pas nécessaire mais utile pour savoir sur quoi se base les boxplots)
  geom_boxplot()+
  theme_bw() 

```



# ### Indices Beta

## Indice de Shannon et Piélou
```{r}
# stabilité des communautés, 0 = 1 espèce prédominante sur sur le récif et 1 = équité de la répartion des espèces
#### indice de Shannon

#matrice présence/absence  par site par espèce
dataR2=dataR %>% ungroup %>%
  select(spp,Site,Day_delta) %>% 
  distinct()%>% 
  group_by(spp,Site,Day_delta) %>% 
  summarize(S=n()) %>%
  na.omit()

dataR4<-spread((dataR3=dataR2 %>% 
  group_by(spp,Site,Day_delta) %>%
  summarize(S2 = mean(S))),key=spp,value=S2)
   # ),key=spp,value=S)
dataR4[is.na(dataR4)]<-0

shannonind<-diversity(dataR4[,-c(1:2)],index="shannon")
shannonind2<-cbind(dataR4[,c(1:2)],shannonind)
colnames(shannonind2)[3]<-"shannon"

#matrice couverture moyenne par site par espèce
dataR2=dataR %>% ungroup %>%
  select(spp,Site,Structure2,Micro,Day_delta,Mcov) %>% 
  distinct()%>% 
  group_by(spp,Site,Structure2,Day_delta,Mcov)

dataR4<-spread((dataR3=dataR2 %>% 
  group_by(spp,Site,Day_delta) %>%
  summarize(Mcov2 = mean(Mcov))),key=spp,value=Mcov2) 
dataR4[is.na(dataR4)]<-0

# Calcul indice de Shannon
shannonind<-diversity(dataR4[,-c(1:2)],index="shannon")
shannonind2<-cbind(dataR4[,c(1:2)],shannonind)
colnames(shannonind2)[3]<-"shannon"

ggplot(shannonind2, aes(Day_delta,shannon, col=Site))+ # Avec "fill" ou "col" du peut ajout une séparation de tes données par facteur (ici le site)
  xlab("Jour depuis immersion")+
  ylab("Indice de Shannon")+
  # geom_jitter(alpha=.3)+  # On ajoute les points (pas nécessaire mais utile pour savoir sur quoi se base les boxplots)
  # geom_boxplot()+
  # geom_smooth()+
  geom_point()+
  geom_line(aes(group=Site))+
  theme_bw() 

#test calcul shannon max théorique
# propmax<-1/ncol(dataR4[,-1])
# shannonmax<- -sum(propmax*log(propmax))

#### indice de Piélou (indice de Shannon/Richesse spécifique)
Piélouind<-shannonind/log(45) #indice de shannon divisé par le nombre max de taxons sur un meme site
Piélouind2<-cbind(dataR4[,c(1:2)],Piélouind)
colnames(Piélouind2)[3]<-"Piélou"
ggplot(Piélouind2, aes(Day_delta,Piélou, col=Site))+ # Avec "fill" ou "col" du peut ajout une séparation de tes données par facteur (ici le site)
  xlab("Jour depuis immersion")+
  ylab("Indice de Shannon")+
  # geom_jitter(alpha=.3)+  # On ajoute les points (pas nécessaire mais utile pour savoir sur quoi se base les boxplots)
  # geom_boxplot()+
  geom_line(aes(group=Site))+
  geom_point()+
  theme_bw() 

```



## Calcul nestedness/replacement/richesse
```{r}
#la nestedness temperature minimale doit etre calculé à partir d'une matrice de meme dimension

# dataR2=dataR %>% ungroup %>% 
#   select(spp,Site,Structure2,Micro,Day_delta) %>% 
#   distinct()%>% 
#   group_by(Site,Structure2,Micro,Day_delta) %>% 
#   summarize(S=n()) %>%
#   na.omit()
# 
# dataR4<-spread((dataR3=dataR2 %>% 
#   filter(Structure2 == "Disc") %>%
#   filter(Site %in% c('Bu','Bi','Fe','VB')) %>% #ne marche pas qu'avec 3 sites minimum
#   group_by(Site,Structure2,Day_delta) %>% 
#   summarize(S2 = mean(S))),key=Site,value=S2)
# dataR4[is.na(dataR4)]<-0
# 
# 
# # resnes<-nestedtemp(dataR2)
# # resnes$p
# 
# library(bipartite)
# seuil<-1
# presence_absence <- dataR4[,-c(1)] >= seuil
# nes<-nestedness(presence_absence)
# 
# nes2<-nested(presence_absence,method="NODF") #valeur élevée = forte Nestedness
# nes3<-nestednodf(presence_absence)
# nested(presence_absence,method='weighted NODF')  #valeur élevée = forte Nestedness mais pondère les espèces en fonction de leur rareté
# 
# nested(presence_absence)
# 
# 
# # été
# dataR2=dataR %>% ungroup %>%
#   filter(saison == 'été') %>% 
#   select(spp,Site,Day_delta) %>% 
#   distinct()%>% 
#   group_by(spp,Site,Day_delta) %>% 
#   summarize(S=n()) %>%
#   na.omit()
# 
# dataR4<-spread((dataR3=dataR2 %>% 
#   group_by(spp,Site,Day_delta) %>%
#   summarize(S2 = mean(S))),key=Site,value=S2) 
# dataR4[is.na(dataR4)]<-0



### Mcov moyen
dataR3=dataR %>% ungroup %>%
  select(spp,Site,Structure2,Micro,Date_courte,Mcov,Quad2) %>%
  distinct()%>%
  group_by(Site,Structure2,Mcov,Micro,Quad2,Date_courte) %>%
  as.data.frame() %>% summarize(Mcov2=mean(Mcov),.by=c(spp,Site,Structure2,Micro,Date_courte)) %>%
  na.omit()%>%
  droplevels() %>% 
  spread(spp,Mcov2) %>% 
  mutate(across(everything(.), ~replace_na(., 0))) %>% 
  mutate(Name=paste(Site,Structure2,Date_courte,sep=","))
 


#Calcul de la nestedness, diversité et turnover
databetadiv2<-beta.div.comp(dataR3[,-c(1:4,65)],coef="S") 
databetadiv2$rich

  

# Extraction des matrices
mat.D=as.matrix(databetadiv2$D)
mat.D[upper.tri(mat.D)]<-NA
diag(mat.D)<-NA
rownames(mat.D)<-dataR3$Name #change le nom des lignes avec les metadonnées
colnames(mat.D)<-dataR3$Name #change le nom des colonnes avec les metadonnées
 
mat.repl=as.matrix(databetadiv2$repl)
mat.repl[upper.tri(mat.repl)]<-NA
diag(mat.repl)<-NA
rownames(mat.repl)<-dataR3$Name #change le nom des lignes avec les metadonnées
colnames(mat.repl)<-dataR3$Name #change le nom des colonnes avec les metadonnées
 
mat.rich=as.matrix(databetadiv2$rich)
mat.rich[upper.tri(mat.rich)]<-NA
diag(mat.rich)<-NA
rownames(mat.rich)<-dataR3$Name #change le nom des lignes avec les metadonnées
colnames(mat.rich)<-dataR3$Name #change le nom des colonnes avec les metadonnées
 

# Transformation des matrices en df
test.mat.D=na.omit(reshape2::melt(mat.D)) %>% mutate(Type='D') 
test.mat.D2 <- test.mat.D %>%
  mutate(row_id = row_number()) %>%  # Créer une colonne pour identifier chaque ligne
  separate(Var1, into = paste0("Var1", 1:3), sep = ",", extra = "drop") %>% #utilise les meta données de la colonne var 1 
  separate(Var2, into = paste0("Var2", 1:3), sep = ",", extra = "drop") %>% #utilise les meta données de la colonne var 2
  select(-row_id)  # Supprimer la colonne d'identification
colnames(test.mat.D2)<-c("Site1","Structure1","Date1","Site2","Structure2","Date2","Dissimilarité","type")


test.mat.repl=na.omit(reshape2::melt(mat.repl)) %>% mutate(Type='repl')
test.mat.repl2 <- test.mat.repl %>%
  mutate(row_id = row_number()) %>%  # Créer une colonne pour identifier chaque ligne
  separate(Var1, into = paste0("Var1", 1:3), sep = ",", extra = "drop") %>% #utilise les meta données de la colonne var 1 
  separate(Var2, into = paste0("Var2", 1:3), sep = ",", extra = "drop") %>% #utilise les meta données de la colonne var 2
  select(-row_id)  # Supprimer la colonne d'identification
colnames(test.mat.repl2)<-c("Site1","Structure1","Date1","Site2","Structure2","Date2","Remplacement","type")


test.mat.rich=na.omit(reshape2::melt(mat.rich)) %>% mutate(Type='rich')
test.mat.rich2 <- test.mat.rich %>%
  mutate(row_id = row_number()) %>%  # Créer une colonne pour identifier chaque ligne
  separate(Var1, into = paste0("Var1", 1:3), sep = ",", extra = "drop") %>% #utilise les meta données de la colonne var 1 
  separate(Var2, into = paste0("Var2", 1:3), sep = ",", extra = "drop") %>% #utilise les meta données de la colonne var 2
  select(-row_id)  # Supprimer la colonne d'identification
colnames(test.mat.rich2)<-c("Site1","Structure1","Date1","Site2","Structure2","Date2","Richesse","type")

```


### Ternary plot
```{r}

# ########## test package Ternary ##########
# library("Ternary")
# TernaryPlot("Nestedness", "Turnover", "Similarité", 
#             grid.lines = 5, grid.lty = "dotted",
#             grid.minor.lines = 1, grid.minor.lty = "dotted",
#             point = "up")
# 
# # Colour the background:
# cols <- TernaryPointValues(rgb)
# ColourTernary(cols, spectrum = NULL)
# 
# # Add data points
# data_points <- list(
#   R = c(255, 0, 0), 
#   O = c(240, 180, 52),
#   Y = c(210, 222, 102),
#   G = c(111, 222, 16),
#   B = c(25, 160, 243),
#   I = c(92, 12, 243),
#   V = c(225, 24, 208)
# )
# 
# data_points <- c(nes$statistic,mean(turn$total),0.5)
# 
# AddToTernary(graphics::points, data_points,col='red')
# 
# AddToTernary(text, data_points, names(data_points), cex = 0.8, font = 2)
# legend("bottomright", 
#        legend = c("Red", "Orange", "Yellow", "Green"),
#        cex = 0.8, bty = "n", pch = 21, pt.cex = 1.8,
#        pt.bg = c(rgb(255,   0,   0, 128, NULL, 255), 
#                  rgb(240, 180,  52, 128, NULL, 255),
#                  rgb(210, 222, 102, 128, NULL, 255),
#                  rgb(111, 222,  16, 128, NULL, 255)))
# 


#Création jeu de données rassemblant les différentes données
datadissi<-test.mat.D2 %>% select(Site1,Structure1,Date1,Site2,Structure2,Date2,Dissimilarité) 
datarepl<-test.mat.repl2 %>% select(Site1,Structure1,Date1,Site2,Structure2,Date2,Remplacement) 
datarich<-test.mat.rich2 %>% select(Site1,Structure1,Date1,Site2,Structure2,Date2,Richesse)

datatern<-cbind(datadissi[,-c(5,7)],Similarité=(1-datadissi[,7])*100,Remplacement=100*datarepl[,7],Richesse=100*datarich[,7])
datatern<-cbind(datadissi[,-c(7)],Similarité=(1-datadissi[,7]),Remplacement=datarepl[,7],Richesse=datarich[,7])


########## Test package gg plot ########## 

 #http://www.ggtern.com/d/2.2.0/
ggtern(data=datatern, aes(x=Richesse,y=Similarité,z=Remplacement)) +
  geom_point(colour='black', position=position_jitter_tern(x=0.1, y=0.1, z=0.1),
             alpha=.1) 
  # geom_crosshair_tern(colour='black')+
  labs(title="")+
  # theme_arrowlarge()+
  theme_noarrows()+
theme_custom(  #https://rdrr.io/cran/ggtern/man/ggtern_themes.html
  base_size = 12,
  base_family = "",
  tern.plot.background = NULL,
  tern.panel.background = NULL,
  col.T = "deepskyblue",
  col.L = "green3",
  col.R = "firebrick1",
  col.grid.minor = "white")


# datatern2=datatern %>%
#   # filter(Structure1 == 'Disc') %>% 
#   # filter(Site1 == 'Bi') %>%
#   filter(Site2 == 'Bi') %>%
#   # filter(Structure1 == "Disc") %>%
#   filter(Date1 == '2022-01') %>%
#   filter(Date2 == '2022-01')

datatern2=datatern %>%
  # filter(Structure1 == 'Disc') %>% 
  filter(Site1 == Site2,
         Structure1==Structure2
         ) %>%
  # filter(Site2 == 'VB')
  # filter(Structure1 == "Di") %>% 
  filter(Date1 == '2021-11') %>%
  filter(Date2 == '2021-11') %>% 
  mutate(Comp_site=Site1,
         Comp_struct=Structure1
         ) 
# %>% 
  # filter(Comp_struct =="Inner_slots")

datatern2=datatern2 %>% 
 mutate(Compasite<-paste(Site1,Site2,sep="/"))
colnames(datatern2)[12]<-"Compasite"



# test pour mettre à  100% (les deux fonctions marchent séparemment mais pas l'une après l'autre)
# datatern2[,c(5:7)] <- round(datatern2[,c(5:7)] / rowSums(datatern2[,c(5:7)]) * 100,1)
# datatern2[,c(5:7)] <-round(datatern2[,c(5:7)],1)

datamean<-datatern2 %>%  group_by(Comp_site,Comp_struct) %>%  #permet de faire la moyenne de chaque colonne par site/struct
  dplyr::summarize(Similarité=mean(Similarité),
            Remplacement=mean(Remplacement),
            Richesse=mean(Richesse))

# datamean<-as.data.frame(t(colMeans(datatern2[,c("Similarité","Richesse","Remplacement")])))

ggtern(data=datatern2, aes(x=Richesse,y=Similarité,z=Remplacement)) +
  geom_point(aes(colour=Comp_struct), position=position_jitter_tern(x=0.1, y=0.1, z=0.1),alpha=.3) +
    # geom_point(aes(fill=Comp_struct), position=position_jitter_tern(x=0.1, y=0.1, z=0.1),alpha=.1) +
  # stat_density_tern( #ajout de la densité
   # geom="polygon",aes(fill=after_stat(level)),bins=10,color='grey')+
  # stat_density_tern(
    #   geom="polygon",aes(fill=Structure1),bins=10,color='grey')+
  # stat_density_tern(
    # geom="polygon",aes(fill=Compasite),bins=10,color='grey')+
  labs(title="")+
# theme_custom(  #https://rdrr.io/cran/ggtern/man/ggtern_themes.html
#   base_size = 10,
#   base_family = "",
#   tern.plot.background = NULL,
#   tern.panel.background = NULL,
#   col.T = "deepskyblue",
#   col.L = "green3",
#   col.R = "firebrick1",
#   col.grid.minor = "white"
# )+
  theme_hidetitles()+ #enlève le nom des axes
  theme_showarrows()+
  geom_crosshair_tern(data=datamean,aes(color=Comp_struct))+
  facet_wrap(.~Comp_site)+
  labs(color = "Structures comparées")

```



# Recouvrement par la roche nue

```{r}
# Quelle est l'évolution de la colonisation de la roche nue au fil du temps?
# Est ce que la diminution de la richesse taxonomique en hiver est démontrée par un nombre d'espèces plus faibles? Par une diminution de la colonisation du récif (augmentation du taux de roche nue(mortalité de la flore/faune sessile))?

dataR2=data_PQ_light %>% ungroup %>%
  filter(spp == "NI") %>%
  filter(!Micro %in% c('C2P3.rndpts.csv','C2P4.rndpts.csv','C2P6.rndpts.csv')) %>% 
  filter(!Site == ("DSC"))%>%
  filter(!Structure2 %in% c('Holes','Upper_slots','Dome')) %>% 
  filter(!Date_courte == '2021-01') %>% 
  select(Site,Date_courte,Structure2,Micro,Quad2,Mcov) %>% 
  group_by(Site,Date_courte,Structure2,Micro,Quad2,Mcov) %>% 
  na.omit() %>% 
  as.data.frame() %>% summarize(Mcov2=mean(Mcov),.by = c(Date_courte,Site,Structure2,Micro)) 

dataR3=dataR2 %>% as.data.frame() %>% 
  summarize(Mcov3=mean(Mcov2),.by = c(Date_courte,Site,Structure2)) 

dataR3=dataR2 %>% as.data.frame() %>% 
  summarize(Mcov3=mean(Mcov2),.by = c(Date_courte,Site)) 


ggplot(dataR3, aes(Structure2,Mcov3, fill=Site))+
  xlab("Structure")+
  ylab("Taux de roche nue")+
  geom_jitter(alpha=.3)+  
  geom_boxplot()+
  theme_bw()  

#Evolution temporelle
ggplot(dataR3, aes(Date_courte,Mcov3, col=Site))+
  xlab("Date")+
  ylab("Taux moyen de roche nue")+
  geom_point()+
  geom_line(aes(group=Site))+
  theme_bw()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```





# Test calcul divers
## Test calcul turnover
```{r}

#proportion relative d'espèces gagnée ou perdue face au nombre total d'espèces observé sur la période 
# 
# dataR2=dataR %>% ungroup %>% 
#    filter(Site == 'Bi') %>%
#   select(spp,Site,Structure2,Day_delta) %>% 
#   distinct()%>% 
#   group_by(spp,Site,Day_delta) %>% 
#   summarize(S=n()) %>%
#   na.omit()
# 
# dataR3=dataR2 %>% 
#   group_by(spp,Site,Day_delta) %>% 
#   summarize(S2 = mean(S))
# 
# 
# turn<-turnover(dataR3,
#                time.var="Day_delta",
#                species.var="spp",
#                abundance.var="S2",
#                metric="total")
# 
# 
# #Dissimilarité de Jaccard
# dataR2<- spread((dataR2=dataR %>% 
#   select(spp,Site,Date_courte,Structure2) %>% 
#   # filter(Date_courte %in% c("2022-04","2022-07"))%>%
#   # filter(Structure2 == ("Disc")) %>%
#   filter(Site == "Bi") %>% 
#   distinct() %>% 
#   group_by(spp,Site,Date_courte) %>% 
#   summarize(S=n())),key=Site,value=S)
# dataR2[is.na(dataR2)]<-0
# 
# similarité_jaccard <- vegdist(dataR2[,3], method = "jaccard")
# 
# similarité_bray <- vegdist(dataR2[,3], method = "bray")
# 
# # library(betapart)
# # dissimilarité_raup_crick<-beta.pair(dataR2,method="raup_crick")
# 
# dissimilarité_raup_crick<-raupcrick(dataR2)
# library(pheatmap)
# pheatmap(1-as.matrix(similarité_jaccard), display_numbers = 1-as.matrix(similarité_jaccard))
# 
```

##### Indice de Jaccard

```{r}
#les sites sont-ils similaires entre eux? 
#Indice de Jaccard entre 0 (pas de similarité) et 1 (sites identiques)
#correspond aux nombres d'observations dans les deux sites / par le nombre dans chaque site


#pour faire avec les données spp
# library(stringdist)
# library(bayesbio)
# stringdist(dataR3[,1],dataR2[,1],method='jaccard')#converti les caractères en données utitilisable
# jaccardSets(dataR2[,1],dataR3[,1])
# 
# #pour faire avec les données spp.ID
# dataR2$spp.ID<-as.numeric(dataR2$spp.ID)
# dataR3$spp.ID<-as.numeric(dataR3$spp.ID)
# jaccard <- function(a, b) {
#     intersection = length(intersect(a, b))
#     union = length(a) + length(b) - intersection
#     return (intersection/union)
# }
# 
# jaccard(dataR2[,-c(2:3)],dataR3[,-c(2:3)])

dataR2=dataR %>% ungroup %>%
  filter(saison == 'été') %>% 
  select(spp,Site) %>% 
  distinct()%>% 
  group_by(spp,Site) %>% 
  summarize(S=n()) %>%
  na.omit()

dataR4<-spread((dataR3=dataR2 %>% 
  group_by(spp,Site) %>%
  summarize(S2 = mean(S))),key=spp,value=S2) 
dataR4[is.na(dataR4)]<-0

jaccardind<-vegdist(dataR4[,-1],index="jaccard")

```

##### Indice de Sorensen
```{r}
#les sites sont-ils similaires entre eux? 
#Indice de Sorensen entre 0 (pas de similarité) et 1 (sites identiques)

dataR2=dataR %>%
  filter(!Date_courte=="2021-01") %>%
  filter(Site=="Bu") %>%
  select(spp.ID,Site) %>% 
  distinct() %>% 
  group_by(spp.ID,Site) %>%
  summarize(S=n())


dataR3=dataR %>% 
  filter(!Date_courte=="2021-01") %>%
  filter(Site=="Fe") %>%
  select(spp.ID,Site) %>% 
  distinct() %>% 
  group_by(spp.ID,Site) %>% 
  summarize(S=n()) 


#pour faire avec les données spp.ID
dataR2$spp.ID<-as.numeric(dataR2$spp.ID)
dataR3$spp.ID<-as.numeric(dataR3$spp.ID)
sorensen <- function(a, b) {
    intersection = 2*length(intersect(a, b))
    union = length(a) + length(b)
    return (intersection/union)
}

sorensen(dataR2[,2],dataR3[,2])

```

##### Indice de Simpson
```{r}
# Montre la diversité taxonomique, 0 étant la présence d'une espèce et 1 une diversité importante
dataR2=dataR %>% ungroup %>%
  filter(saison == 'été') %>% 
  select(spp,Site) %>% 
  distinct()%>% 
  group_by(spp,Site) %>% 
  summarize(S=n()) %>%
  na.omit()

dataR4<-spread((dataR3=dataR2 %>% 
  group_by(spp,Site) %>%
  summarize(S2 = mean(S))),key=spp,value=S2) 
dataR4[is.na(dataR4)]<-0

simpsonind<-diversity(dataR4[,-1],index="simpson")

```
