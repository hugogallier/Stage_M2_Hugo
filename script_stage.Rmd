---
title: "script_analyse_test"
author: "Hugo Gallier"
date: "2024-01-23"
output: html_document
editor_options: 
  chunk_output_type: console
---


# Library

Package à télécharger
```{r}
rm(list=ls())

library(dplyr)
library(tidyr)
library(ggplot2)
library(here)
library(vegan)
library(scales)
library(fmsb)
library(FactoMineR)
library(ecodist)
library(ade4)
library(lme4)
library(Matrix)
library(sjPlot)
library(RColorBrewer)
library(iNEXT)
library(rstatix)
library(ggradar)
library(pairwiseAdonis)
library(ecole)
library(tidyverse)
library(mgcv)
library(ggforce)

```


#################### Importation du data et chargement ###################

```{r}
#Chargement des photos associées à chaque cadrats

setwd(here::here())

MPhoto=read.csv('Meta_photo.csv', sep=';')%>%
  # mutate(Micro=) %>%
  mutate(Micro=sub("\\_.*", "", Code_struct))
  
```

## Chargement data

```{r}
#Chargement des jeux de données

setwd('D:/Hugo/suivi_scientifique') # à modifier avec nom de ton DD
# setwd('E:/Marineff/suivi_scientifique')

data_list=list.files(pattern =".csv", recursive=T)

L=list()
for( i in 1: length(data_list)){
  
    Name_file=basename(data_list[i])

data=read.csv(data_list[i], sep=',', header=T, fileEncoding="latin1") %>%
  mutate(Name_file=rep(basename(data_list[i]), n()))

L[[i]]<-data

}


test_data_list=data_list[grepl('DSC',data_list)]


# fileEncoding="latin1"
```

## Date d'immersion

```{r}
# Ajout des dates d'immersion des différents récifs

Immer_site=data.frame(Site=c('Bi','Bu','VB','Fe'), Date=c(as.Date('2020-10-30'),as.Date('2020-11-26'),as.Date('2020-11-27'),as.Date('2020-11-30'))) %>%
       mutate(Date_imm_ok=format(as.POSIXlt(Date,  format = "%Y-%m-%d"), format="%Y-%m-%d", tz="GMT")) %>% select(Site, Date_imm_ok)
     
# Date=c(as.Date('2020-10-30'),as.Date('2020-11-26'),as.Date('2020-11-27'),as.Date('2020-11-30'))) %>%
       # mutate(Date_imm_ok=format(as.POSIXlt(Date,  format = "%Y-%m-%d"), format="%Y-%m-%d %%H:%M:%S", tz="GMT")) %>% select(Site, Date_imm_ok)    
```

## Saison - date

```{r}
# Ajout de dates correspondant aux différentes saisons
Date_sais=data.frame(
           start=c(
             format(as.POSIXlt(as.Date('2021-03-20'),  format = "%Y-%m-%d"), format="%Y-%m-%d %%H:%M:%S", tz="GMT"),
             format(as.POSIXlt(as.Date('2021-06-21'),  format = "%Y-%m-%d"), format="%Y-%m-%d %%H:%M:%S", tz="GMT"),
             format(as.POSIXlt(as.Date('2021-09-22'),  format = "%Y-%m-%d"), format="%Y-%m-%d %%H:%M:%S", tz="GMT"),
             format(as.POSIXlt(as.Date('2021-12-21'),  format = "%Y-%m-%d"), format="%Y-%m-%d %%H:%M:%S", tz="GMT"),
      format(as.POSIXlt(as.Date('2022-03-20'),  format = "%Y-%m-%d"), format="%Y-%m-%d %%H:%M:%S", tz="GMT"),
      format(as.POSIXlt(as.Date('2022-06-21'),  format = "%Y-%m-%d"), format="%Y-%m-%d %%H:%M:%S", tz="GMT"),
       format(as.POSIXlt(as.Date('2022-09-22'),  format = "%Y-%m-%d"), format="%Y-%m-%d %%H:%M:%S", tz="GMT")))
```


## Mise en forme des données


```{r}
# Ajout de méta données à partir du nom de fichier (site,data,micro,n° de quadrat)
# Correction et abbréviation des noms de taxons
# Changements des noms des microhabitats
# Changements du format des dates


# test_dataPQ=data_PQ[grepl('DSC',data_PQ$Name_file),]

data_PQ=do.call(rbind,L) %>%
  mutate(Site=substr(Name_file, start = 1, stop = 2)) %>%
  separate(col = Name_file, into = c('Site','Date','Micro','truc','Quad'), sep = '_') %>%
  mutate( Site=ifelse(Site=='FR','Fe',Site),
          Quad=ifelse(is.na(Quad),truc,Quad),
          Quad2=substr(Quad, start = 1, stop = 2),
          Month_str=gsub("-.*", "", Date,perl=TRUE),
          YY=gsub(".*-", "", Date,perl=TRUE),
          Month=case_when( Month_str=='Avri'~'04',
                           Month_str=='avri'~'04',
                           Month_str=="Janv"~'01',
                           Month_str=='Juil'~'07',
                           Month_str=='Oct'~'10',
                           Month_str=='Nov'~'11'),
          Date_ok=format(as.POSIXlt(paste0('01/',Month,'/',YY),  format = "%d/%m/%y"), format="%Y-%m-%d %%H:%M:%S", tz="GMT"),
          Date_courte=format(as.POSIXlt(paste0('01/',Month,'/',YY),  format = "%d/%m/%y"), format="%Y-%m", tz="GMT"),
          Week=strftime(Date_ok, format = "%V")) %>%
  mutate(spp.Name= ifelse(spp.Name == 'Tubularia indivisa ', 'Tubularia indivisa',spp.Name),
         spp.Name=ifelse(spp.Name == 'Unidentified','NI',spp.Name))
  

# <<<<<<< HEAD
# test=data_PQ[is.na(data_PQ$Date_courte),]
# 
# test=data_PQ %>% filter(Site =='Fe',
#                         Date =="Nov-21")

# >>>>>>> d7a3076aa8c86cd4609b46ec0f575f800cd1d573

# Version synthétique du df

data_PQ_light=data_PQ %>% dplyr::select(Image, spp.Name,spp.ID,N.pts.per.species,Cov..per.species,
               N.pts.ALL.species,Cov..ALL.species, Site,Date_ok,Micro,Quad2,
               Week,Date_courte,Month_str )%>%
rename('spp'='spp.Name',
       'Count'='N.pts.per.species',
       'Cov'='Cov..per.species',
       'Count_all'='N.pts.ALL.species',
       'Cov_all'='Cov..ALL.species')%>%
  mutate(abb=abbreviate(spp))%>%
   group_by(spp,abb,Site,Micro,Date_courte,Date_ok) %>%
# <<<<<<< HEAD
  summarize(Mcov=mean(Cov)) %>%
  # summarize(MCount=mean(Count)) %>%
# =======
  # summarize(Mcov=mean(Cov),
  #           Mcount=mean(Count)) %>%
# >>>>>>> 85e13e91955f931dac262e7c430572b75e53e18d
  left_join(MPhoto, by=c('Micro')) %>%
  mutate(Structure2=recode_factor(Structure,
   "Bandes"="Dome",
   "Bandes.C1"="Disc",
   "Faille"="Inner_slots",
   "Faille_coupole"="Upper_slots",
   "Pilier.C2"="Columns",
   "Trous"="Holes",
   "Pieds"="Pillars"))%>% 
  mutate(Strcut_groups=case_when(
  Structure2 %in% c('Dome','Upper_slots')~'Horizontal_section',
 Structure2 %in% c('Disc','Columns','Pillars')~'Vertical_section',
  Structure2 %in% c('Inner_slots','Holes')~'Inner_section', TRUE ~ 'NA')) %>%
  mutate(M_ensemble=ifelse(Micro %in% c("P1","P2","P3","T1","T2","T3","T4"),substr(Micro, start = 1, stop = 1),substr(Micro, start = 1, stop = 3)),
         M_ensemble2=ifelse(M_ensemble == 'DPF','DGF',M_ensemble))%>%
  left_join(Immer_site, by='Site') %>% 
    mutate(spp=replace_na(spp,"None"))
 

knitr::kable(data_PQ_light %>% select(spp,abb)%>% unique())
corresp=data_PQ_light %>% select(spp,abb)%>% unique()
```



# #######################

# ###### Partie Hugo ######
# Formatage du jeu de données 
```{r}
dataR1<-data_PQ_light
dataR=dataR1 %>% filter(!spp %in% c("NI","Unassigned","ponte","Ponte",'None','NA')) %>%
  filter(!Micro %in% c('C2P3.rndpts.csv','C2P4.rndpts.csv','C2P6.rndpts.csv')) %>% 
  filter(!Site == ("DSC"))%>%
  filter(!Structure2 %in% c('Holes','Upper_slots','Dome')) %>% 
  select (spp,abb,Site,Micro,Date_courte,Structure2,Mcov)
  # select (spp,abb,Site,Micro,Date_courte,Structure2,MCount)

# save(dataR,file="dataR.Rdata")

```

# ### Indice Gamma
```{r}
# Quel est la richesse taxonomique global (Indice Gamma) d'un site et de la zone d'étude en général

# Indice gamma par site 
dataR2=dataR %>% ungroup %>% 
  select(spp,Site,Date_courte) %>% 
  filter(Date_courte  %in% c('2021-04','2021-07','2021-10','2021-11')) %>%
  filter(Site == "Fe") %>%
  distinct()%>% 
  group_by(spp,Date_courte,Site) %>% 
  summarize(S=n()) %>%
  na.omit()
length(unique(dataR2$spp))


seq<-rep(0,times=nrow(dataR))
dataR
dataR2=dataR %>% 
  select(spp,Site) %>% 
  distinct() %>% 
  group_by(spp,Site) %>% 
  summarize(S=n()) 
length(unique(dataR2$spp))


# Indice gamma Quad2# Indice gamma global
dataR2=dataR %>% 
  select(spp,seq1) %>% 
  distinct() %>% 
  group_by(seq1) %>% 
  summarize(S=n()) 


length(unique(dataR1$spp))#permet de savoir le nombre de variable différente dans la colonne spp (mais ne prend pas en compte la suppression des N)

```


# ### Indice Alpha 


# Comparaison intersite et intrasite
## Comparaison intersite 2021-2022 (pas de temporalité saisonalle)
```{r}
#Y'a t'il une différence de richesse taxonomique entre les différents micro habitats, et selon les différents sites ainsi que selon les années?

dataR3=dataR %>% ungroup %>% 
  select(spp,Site,Structure2,Date_courte) %>% 
  # filter(Structure2 == "Disc") %>%
  # filter(Site == "VB") %>%
  # filter(Structi %in% c('CGF1','CGF2','CGF3','CGF4','CPF1','CPF2','CPF3','CPF4'))%>%
  distinct()%>% 
  group_by(Site,Structure2,Date_courte) %>%
  summarize(S=n()) %>%
  na.omit() 

length(unique(dataR3$spp))

ggplot(dataR3, aes(Site,S, fill=Structure2))+ # Avec "fill" ou "col" du peut ajout une séparation de tes données par facteur (ici le site)
  xlab("Structure")+
  ylab("Richesse taxonomique")+
  geom_jitter(alpha=.3)+  # On ajoute les points (pas nécessaire mais utile pour savoir sur quoi se base les boxplots)
  geom_boxplot()+
  theme_bw()  # Juste pour retirer le fond gris pas défaut (--> moche !)

```

#### Version Bruno

```{r}

# Plot1: Visualition différences entre sites pour chaque micro habitat

ggplot(dataR2, aes(Structure2,S, fill=Site))+ # Avec "fill" ou "col" du peut ajout une séparation de tes données par facteur (ici le site)
  xlab("Structure")+
  ylab("Richesse taxonomique")+
  geom_jitter(alpha=.3)+  # On ajoute les points (pas nécessaire mais utile pour savoir sur quoi se base les boxplots)
  geom_boxplot()+
  theme_bw()  # Juste pour retirer le fond gris pas défaut (--> moche !)


# Plot 2 : Visualisation des différences de chaque micro habitat par Site

ggplot(dataR2, aes(Site,S, fill=Structure2))+ 
  xlab("Site")+
  ylab("Richesse taxonomique")+
  geom_jitter(alpha=.3)+  
  geom_boxplot()+
  theme_bw() 

```


###Test Shapiro/Levene/Anova
```{r}

dataR3=dataR %>% ungroup %>% 
  select(spp,Site,Date_courte) %>% 
  filter(Date_courte %in% c('2022-01','2022-04','2022-07','2022-11')) %>%
  distinct()%>% 
  group_by(Site,Date_courte) %>%
  summarize(S=n()) %>%
  na.omit() 

# test_levene<-levene_test(S~Structure2)
# model1<-lm(S~Structure2,data=dataR2021)
# shapiro_test(residuals(model1))#si pvalue supérieure à 0,05 alors permet de dire que les résidus sont normalements distribuées
# 
# leveneTest(S~Structure2,data=dataR2021)#Si p value supérieur à 0,05 alors variance entre les groupes est égale


test_anova<-aov(S~Site,data=dataR3)#anova en prenant la date ainsi que les structures comme facteur

summary(test_anova)

```

# Comparaison intersite (microhabitats confondus) temporelle
```{r}

dataR2=dataR %>% ungroup %>% 
  filter(!Date_courte=="2021-01") %>%
  select(spp,Site,Date_courte) %>% 
  distinct() %>% 
  group_by(Site,Date_courte) %>% 
  summarize(S=n()) %>% 
  na.omit()



ggplot(dataR2, aes(Date_courte,S, col=Site))+
  xlab("Date")+
  ylab("Richesse taxonomique")+
  geom_point()+
  geom_line(aes(group=Site))+
  # facet_wrap(.~Site)+ # <- cette fonction permet de réaliser les geoms précedents mais pour différentes catégories (ici j'ai choisi les micro habitat, mais on aurait pu le faire pour les sites par exemples)
  theme_bw()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) # <- rotation des dates pour qu'elles soient lisibles

```

# Comparaison intersite des microhabitats - temporelle
```{r}
# Y'a t'il une différence temporelle dans l'évolution de la richesse taxnomique des microhabitats?

dataR2=dataR %>% ungroup %>% 
  filter(!Date_courte=="2021-01") %>%
  select(spp,Site,Date_courte,Structure2) %>% 
  distinct() %>% 
  group_by(Site,Date_courte,Structure2) %>% 
  summarize(S=n()) %>% 
  na.omit()


ggplot(dataR2 %>%  
  filter(!Date_courte=="2021-01"), 
  aes(Date_courte,S, col=Site))+
  xlab("Date")+
  ylab("Richesse taxonomique")+
  geom_point()+
  geom_line(aes(group=Site))+
  facet_wrap(.~Structure2)+ 
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) 

```

# Radar plot
```{r}
# https://r-charts.com/ranking/ggradar/
# devtools::install_github("ricardo-bion/ggradar")


##### Bottom disc #####
lcol2<-brewer.pal(8,"Reds")
lcol2<-c('#FEE0D2','#FCBBA1','#FC9272','#FB6A4A','#EF3B2C','#CB181D','#99000D','#59040c')

# Bi
resultat4Bi<- na.omit(spread((dataR2=dataR %>% 
  filter(!Date_courte == ("2021-01"))%>%
  filter(Site == ("Bi"))%>%
  filter(Micro %in% c("C1B1","C1B2","C1B3","C1B4","C1B5","C1B6","C1B7","C1B8"))%>%
  select(spp,Site,Date_courte,Micro) %>% 
  distinct() %>% 
  group_by(Site,Date_courte,Micro) %>% 
  summarize(S=n())),key=Micro,value=S)) 
resultat4Bi[is.na(resultat4Bi)]<-0

ggradar(resultat4Bi[,-1],grid.min = 0,grid.mid=7,grid.max =15,values.radar = c(0,7,15),group.colours = lcol2[c(1,2,4:8)],legend.title="Site Bi",gridline.max.linetype = 1,gridline.max.colour = "black",gridline.min.linetype = 1,gridline.min.colour="black",gridline.mid.linetype = 1,gridline.mid.colour="black",background.circle.colour = "lightblue")


# Bu
resultat4Bu<- na.omit(spread((dataR2=dataR %>% 
  filter(!Date_courte == ("2021-01"))%>%
  filter(Site == ("Bu"))%>%
  filter(Micro %in% c("C1B1","C1B2","C1B3","C1B4","C1B5","C1B6","C1B7","C1B8"))%>%
  select(spp,Site,Date_courte,Micro) %>% 
  distinct() %>% 
  group_by(Site,Date_courte,Micro) %>% 
  summarize(S=n())),key=Micro,value=S)) 
resultat4Bu[is.na(resultat4Bu)]<-0

ggradar(resultat4Bu[,-1],grid.min = 0,grid.mid=7, grid.max =15,values.radar = c(0,7,15),group.colours = lcol2[c(2,4,6,8)],legend.title="Site Bu",gridline.max.linetype = 1,gridline.max.colour = "black",gridline.min.linetype = 1,gridline.min.colour="black",gridline.mid.linetype = 1,gridline.mid.colour="black",background.circle.colour = "lightblue")

# Fe
resultat4Fe<- na.omit(spread((dataR2=dataR %>%
  filter(!Date_courte == ("2021-01"))%>%
  filter(Site == ("Fe"))%>%
  filter(Micro %in% c("C1B1","C1B2","C1B3","C1B4","C1B5","C1B6","C1B7","C1B8"))%>%
  select(spp,Site,Date_courte,Micro) %>% 
  distinct() %>% 
  group_by(Site,Date_courte,Micro) %>% 
  summarize(S=n())),key=Micro,value=S)) 
resultat4Fe[is.na(resultat4Fe)]<-0

ggradar(resultat4Fe[,-1],grid.min = 0,grid.mid=7,grid.max =15,values.radar = c(0,7,15),group.colours = lcol2[c(1,4,5,6,7)], legend.title="Site Fe",gridline.max.linetype = 1,gridline.max.colour = "black",gridline.min.linetype = 1,gridline.min.colour="black",gridline.mid.linetype = 1,gridline.mid.colour="black",background.circle.colour = "lightblue")


# VB
resultat4VB<- na.omit(spread((dataR2=dataR %>%
  filter(!Date_courte == ("2021-01"))%>%
  filter(Site == ("VB"))%>%
  filter(Micro %in% c("C1B1","C1B2","C1B3","C1B4","C1B5","C1B6","C1B7","C1B8"))%>%
  select(spp,Site,Date_courte,Micro) %>% 
  distinct() %>% 
  group_by(Site,Date_courte,Micro) %>% 
  summarize(S=n())),key=Micro,value=S))
resultat4VB[is.na(resultat4VB)]<-0

ggradar(resultat4VB[,-1],grid.min = 0,grid.mid= 7,grid.max =15,values.radar = c(0,7,15),group.colours =lcol2[c(1:5,7:8)], legend.title="Site VB",gridline.max.linetype = 1,gridline.max.colour = "black",gridline.min.linetype = 1,gridline.min.colour="black",gridline.mid.linetype = 1,gridline.mid.colour="black",background.circle.colour = "lightblue")

##### Columns #####
par(mfrow=c(2,2))
#Bi
resultat3Bi<- na.omit(spread((dataR2=dataR %>% 
  filter(!Date_courte == ("2021-01"))%>%
  filter(Site == ("Bi"))%>%
  filter(Micro %in% c("C2P1","C2P2","C2P3","C2P4","C2P5","C2P6","C2P7","C2P8"))%>%
  select(spp,Site,Date_courte,Micro) %>% 
  distinct() %>% 
  group_by(Site,Date_courte,Micro) %>% 
  summarize(S=n())),key=Micro,value=S)) 
resultat3Bi[is.na(resultat3Bi)]<-0

ggradar(resultat3Bi[,-1],grid.min = 0,grid.max =10,grid.mid=5,values.radar = c(0,5,10),group.colours =lcol2[c(1,4,5,6,8)],legend.title="Site Bi",gridline.max.linetype = 1,gridline.max.colour = "black",gridline.min.linetype = 1,gridline.min.colour="black",gridline.mid.linetype = 1,gridline.mid.colour="black",background.circle.colour = "lightblue")


#Bu
resultat3Bu<- na.omit(spread((dataR2=dataR %>%
  filter(Site == ("Bu"))%>%
  filter(Micro %in% c("C2P1","C2P2","C2P3","C2P4","C2P5","C2P6","C2P7","C2P8"))%>%
  select(spp,Site,Date_courte,Micro) %>% 
  distinct() %>% 
  group_by(Site,Date_courte,Micro) %>% 
  summarize(S=n())),key=Micro,value=S))
resultat3Bu[is.na(resultat3Bu)]<-0

ggradar(resultat3Bu[,-1],grid.min = 0,grid.max =10,grid.mid=5,values.radar = c(0,5,10),group.colours =lcol2[c(1,2,4,5,8)],legend.title="Site Bu",gridline.max.linetype = 1,gridline.max.colour = "black",gridline.min.linetype = 1,gridline.min.colour="black",gridline.mid.linetype = 1,gridline.mid.colour="black",background.circle.colour = "lightblue")


#Fe
resultat3Fe<- na.omit(spread((dataR2=dataR %>% 
  filter(!Date_courte == ("2021-01"))%>%
  filter(Site == ("Fe"))%>%
  filter(Micro %in% c("C2P1","C2P2","C2P3","C2P4","C2P5","C2P6","C2P7","C2P8"))%>%
  select(spp,Site,Date_courte,Micro) %>% 
  distinct() %>% 
  group_by(Site,Date_courte,Micro) %>% 
  summarize(S=n())),key=Micro,value=S))
resultat3Fe[is.na(resultat3Fe)]<-0

ggradar(resultat3Fe[,-1],grid.min = 0,grid.max =10,grid.mid=5,values.radar = c(0,5,10),group.colours =lcol2[c(1,5,7)] ,legend.title="Site Fe",gridline.max.linetype = 1,gridline.max.colour = "black",gridline.min.linetype = 1,gridline.min.colour="black",gridline.mid.linetype = 1,gridline.mid.colour="black",background.circle.colour = "lightblue")


#VB
resultat3VB<- na.omit(spread((dataR2=dataR %>%
  filter(!Date_courte == ("2021-01"))%>%
  filter(Site == ("VB"))%>%
  filter(Micro %in% c("C2P1","C2P2","C2P3","C2P4","C2P5","C2P6","C2P7","C2P8"))%>%
  select(spp,Site,Date_courte,Micro) %>% 
  distinct() %>% 
  group_by(Site,Date_courte,Micro) %>% 
  summarize(S=n())),key=Micro,value=S))
resultat3VB[is.na(resultat3VB)]<-0

ggradar(resultat3VB[,-1],grid.min = 0,grid.max =10,grid.mid=5,values.radar = c(0,5,10),group.colours =lcol2[c(1:3,5,6,8)] ,legend.title="Site VB",gridline.max.linetype = 1,gridline.max.colour = "black",gridline.min.linetype = 1,gridline.min.colour="black",gridline.mid.linetype = 1,gridline.mid.colour="black",background.circle.colour = "lightblue")


```


# Linear mixed model
```{r}
#Permet de montrer la significativité des valeurs selon des variables aléatoires

dataR2=dataR %>%
  filter(!Date_courte=="2021-01") %>%
  select(spp,Site,Date_courte,Micro,Structure2) %>% 
  distinct() %>% 
  group_by(Site,Date_courte,Micro,Structure2) %>% #filtre selon le site, date et structure
  summarize(S=n()) #créér une nouvelle colonne permettant de faire un summary des valeurs filtrées


plot(lm(S~Site,data=dataR2))
mixed.lmer <- lmer(S ~ Site + (1|Micro/Date_courte), data = dataR2) #compare les données de richesse taxo avec les variables aléatoires qui sont Micro et date courte
summary(mixed.lmer)
plot_model(mixed.lmer,show.values = T,show.p = T)#montre que par rapport à un site de réference (ici Bi), les autres sites sont différents. Ici Fetlar a plutot une diversité moindre que Bi mais est le plus proche. 
tab_model(mixed.lmer)

```

# Generalized linear model
```{r}
#Permet de montrer la significativité des valeurs selon des variables aléatoires

dataR2=dataR %>% ungroup %>% 
  filter(!Date_courte=="2021-01") %>%
  select(spp,Site,Date_courte) %>% 
  distinct() %>% 
  group_by(Site,Date_courte) %>% #filtre selon le site, date et structure
  summarize(S=n()) #créér une nouvelle colonne permettant de faire un summary des valeurs filtrées

glm1<-glm(S~Date_courte,data=dataR2)
summary(glm1)



# dataR2$ecart<-as.numeric(dataR2$Date_courte-Immer_site[1,2])
# dataR2$diff=(difftime(dataR2$Date_courte,Immer_site[1,2],units="weeks"))
# 
# # Chargement des packages
# library(dplyr)

# # Création de dataframes fictifs
# dataR4<-dataR2[,2]
# dataR4$date_with_day <- as.Date(paste0(dataR4$Date_courte, "-01"))
# as.Date(dataR4$date_with_day,format='%Y-%m-%d') 
# 
# as.Date(Immer_site$Date_imm_ok,format='%Y-%m-%d')
# 
# # Calcul de la différence en jours entre chaque date de df1 et les dates de df2
# result <- sapply(df1$date_col, function(x) {
#   sapply(df2$other_date_col, function(y) {
#     as.numeric(difftime(x, y, units = "days"))
#   })
# })
# 
# # Transformation du résultat en dataframe
# result_df <- as.data.frame(result)
# rownames(result_df) <- paste0("date_", 1:nrow(df1))
# colnames(result_df) <- paste0("other_date_", 1:nrow(df2))
# 
# # Affichage du résultat
# print(result_df)


# dataR2$nummois= dataR2$nummois %>%
#   ifelse(dataR2$nummois=="2021-04",zero,trois)
# 
#   if(dataR2$nummois == "2021-04"){0
#   }else if (dataR2$nummois == "2021-07"){3
#   }else if (dataR2$nummois == "2021-10"){6
#   }else if (dataR2$nummois == "2021-11"){7
#   }else if (dataR2$nummois == "2022-01"){9
#   }else if (dataR2$nummois == "2022-04"){12
#   }else if (dataR2$nummois == "2021-07"){15
#   }else{19}
# 
# 
# dataR2$new_date <- ifelse(dataR2$Date_courte == "2021-04",0,3) %>% 
#   ifelse(dataR2$Date_courte=="2021-07",3,1)
#   else(dataR2$Date_courte == "2021-07",3)



load("dataR.Rdata")
dataR$nummois<-dataR$Date_courte
dataR$nummois[dataR$nummois == "2021-04" & dataR$Site=="Bi"] <- 153
dataR$nummois[dataR$nummois == "2021-07" & dataR$Site=="Bi"] <- 244
dataR$nummois[dataR$nummois == "2021-10" & dataR$Site=="Bi"] <- 336
dataR$nummois[dataR$nummois == "2021-11" & dataR$Site=="Bi"] <- 367
dataR$nummois[dataR$nummois == "2022-01" & dataR$Site=="Bi"] <- 428
dataR$nummois[dataR$nummois == "2022-04" & dataR$Site=="Bi"] <- 518
dataR$nummois[dataR$nummois == "2022-07" & dataR$Site=="Bi"] <- 609
dataR$nummois[dataR$nummois == "2022-11" & dataR$Site=="Bi"] <- 732

dataR$nummois[dataR$nummois == "2021-04" & dataR$Site=="Bu"] <- 126
dataR$nummois[dataR$nummois == "2021-07" & dataR$Site=="Bu"] <- 217
dataR$nummois[dataR$nummois == "2021-10" & dataR$Site=="Bu"] <- 309
dataR$nummois[dataR$nummois == "2021-11" & dataR$Site=="Bu"] <- 340
dataR$nummois[dataR$nummois == "2022-01" & dataR$Site=="Bu"] <- 401
dataR$nummois[dataR$nummois == "2022-04" & dataR$Site=="Bu"] <- 491
dataR$nummois[dataR$nummois == "2022-07" & dataR$Site=="Bu"] <- 582
dataR$nummois[dataR$nummois == "2022-11" & dataR$Site=="Bu"] <- 705

dataR$nummois[dataR$nummois == "2021-04" & dataR$Site=="Fe"] <- 127
dataR$nummois[dataR$nummois == "2021-07" & dataR$Site=="Fe"] <- 218
dataR$nummois[dataR$nummois == "2021-10" & dataR$Site=="Fe"] <- 310
dataR$nummois[dataR$nummois == "2021-11" & dataR$Site=="Fe"] <- 241
dataR$nummois[dataR$nummois == "2022-01" & dataR$Site=="Fe"] <- 402
dataR$nummois[dataR$nummois == "2022-04" & dataR$Site=="Fe"] <- 492
dataR$nummois[dataR$nummois == "2022-07" & dataR$Site=="Fe"] <- 583
dataR$nummois[dataR$nummois == "2022-11" & dataR$Site=="Fe"] <- 706

dataR$nummois[dataR$nummois == "2021-04" & dataR$Site=="VB"] <- 130
dataR$nummois[dataR$nummois == "2021-07" & dataR$Site=="VB"] <- 221
dataR$nummois[dataR$nummois == "2021-10" & dataR$Site=="VB"] <- 313
dataR$nummois[dataR$nummois == "2021-11" & dataR$Site=="VB"] <- 344
dataR$nummois[dataR$nummois == "2022-01" & dataR$Site=="VB"] <- 405
dataR$nummois[dataR$nummois == "2022-04" & dataR$Site=="VB"] <- 495
dataR$nummois[dataR$nummois == "2022-07" & dataR$Site=="VB"] <- 586
dataR$nummois[dataR$nummois == "2022-11" & dataR$Site=="VB"] <- 709

dataR$saison<-dataR$Date_courte
dataR$saison[dataR$saison == "2021-04" | dataR$saison == "2022-04"] <- "printemps"
dataR$saison[dataR$saison == "2021-07" | dataR$saison == "2022-07"] <- "été"
dataR$saison[dataR$saison == "2021-10" | dataR$saison == "2021-11"| dataR$saison == "2022-11"] <- "automne"
dataR$saison[dataR$saison == "2022-01"] <- "hiver"





dataR2=dataR %>% ungroup %>% 
  filter(!Date_courte=="2021-01") %>%
  select(spp,Site,Date_courte,Structure2,nummois,saison) %>% 
  distinct() %>% 
  group_by(Site,nummois,Structure2,Date_courte,saison) %>% #filtre selon le site, date et structure
  summarize(S=n()) 
 
glm1<-glm(S~Date_courte,data=dataR2,family=poisson)
plot(glm1)
summary(glm1)
```


# Vitesse de colonisation 
```{r}
# à utiliser avec les les lignes de dataR$nummois d'avant
seq<-c(0,0)
seq2<-c(0,0,0)

dataR21=dataR %>% ungroup %>%   
  select(spp,Site,Date_courte,nummois) %>% 
  filter(!Date_courte=="2021-01") %>%
  filter(Site %in% c('Bi')) %>% 
  # filter(Structure2=='Disc') %>% 
  distinct() %>% 
  group_by(Site,nummois) %>% #filtre selon le site, date et structure
  summarize(S=n()) 

dataR2Bi<-dataR21$Site[-1]
dataR21$nummois<-as.numeric(dataR21$nummois)
dataR21$S<-as.numeric(dataR21$S)
dataR21<-dataR21[,-1]
dataR21<-rbind(seq,dataR21)
dataR3<-dataR21[-1,]-dataR21[-nrow(dataR21),]
dataR3$SparT<-dataR3$S/dataR3$nummois



dataR22=dataR %>% ungroup %>%   
  select(spp,Site,Date_courte,nummois) %>% 
  filter(!Date_courte=="2021-01") %>%
  filter(Site %in% c('Bu')) %>% 
  # filter(Structure2=='Disc') %>% 
  distinct() %>% 
  group_by(Site,nummois) %>% #filtre selon le site, date et structure
  summarize(S=n()) 

dataR2Bu<-dataR22$Site[-1]
dataR22$nummois<-as.numeric(dataR22$nummois)
dataR22$S<-as.numeric(dataR22$S)
dataR22<-dataR22[,-1]
dataR22<-rbind(seq,dataR22)
dataR4<-dataR22[-1,]-dataR22[-nrow(dataR22),]
dataR4$SparT<-dataR4$S/dataR4$nummois



dataR23=dataR %>% ungroup %>%   
  select(spp,Site,Date_courte,nummois) %>% 
  filter(!Date_courte=="2021-01") %>%
  filter(Site %in% c('Fe')) %>% 
  # filter(Structure2=='Disc') %>% 
  distinct() %>% 
  group_by(Site,nummois) %>% #filtre selon le site, date et structure
  summarize(S=n()) 

dataR2Fe<-dataR23$Site[-1]
dataR23$nummois<-as.numeric(dataR23$nummois)
dataR23$S<-as.numeric(dataR23$S)
dataR23<-dataR23[,-1]
dataR23<-rbind(seq,dataR23)
dataR5<-dataR23[-1,]-dataR23[-nrow(dataR23),]
dataR5$SparT<-dataR5$S/dataR5$nummois




dataR24=dataR %>% ungroup %>%   
  select(spp,Site,Date_courte,nummois) %>% 
  filter(!Date_courte=="2021-01") %>%
  filter(Site %in% c('VB')) %>% 
  # filter(Structure2=='Disc') %>% 
  distinct() %>% 
  group_by(Site,nummois) %>% #filtre selon le site, date et structure
  summarize(S=n()) 

dataR2VB<-dataR24$Site[-1]
dataR24$nummois<-as.numeric(dataR24$nummois)
dataR24$S<-as.numeric(dataR24$S)
dataR24<-dataR24[,-1]
dataR24<-rbind(seq,dataR24)
dataR6<-dataR24[-1,]-dataR24[-nrow(dataR24),]
dataR6$SparT<-dataR6$S/dataR6$nummois



# dataR2total<-rbind(dataR2Bi,dataR2Bu,dataR2Fe,dataR2VB)
# dataR7<-cbind(dataR2$Site,dataR3$SparT,dataR4$SparT,dataR5$SparT,dataR6$SparT)

plot(dataR3$SparT~dataR21$nummois[-1],col="red",xlim=c(100,800),ylim=c(-0.2,0.2),pch=19,xlab="Nombre de jours",ylab="Nombre d'espèces colonisant par jour")
par(new=T)
plot(dataR4$SparT~dataR22$nummois[-1],col="blue",xlim=c(100,800),ylim=c(-0.2,0.2),pch=19,xlab="",ylab="")
par(new=T)
plot(dataR5$SparT~dataR23$nummois[-1],col="green",xlim=c(100,800),ylim=c(-0.2,0.2),pch=19,xlab="",ylab="")
par(new=T)
plot(dataR6$SparT~dataR24$nummois[-1],col="black",xlim=c(100,800),ylim=c(-0.2,0.2),pch=19,xlab="",ylab="")
lines(dataR4$SparT~dataR22$nummois[-1],col="blue",xlim=c(100,800),ylim=c(-0.2,0.2),pch=19,xlab="",ylab="")
lines(dataR5$SparT~dataR23$nummois[-1],col="green",xlim=c(100,800),ylim=c(-0.2,0.2),pch=19,xlab="",ylab="")
lines(dataR3$SparT~dataR21$nummois[-1],col="red",xlim=c(100,800),ylim=c(-0.2,0.2),pch=19,xlab="",ylab="")
lines(dataR6$SparT~dataR24$nummois[-1],col="black",xlim=c(100,800),ylim=c(-0.2,0.2),pch=19,xlab="",ylab="")
legend(x = "bottomright", legend = c("Bi","Bu","Fe","VB"),lty = 1, col = c("red","blue","green","black"),lwd = 2)


# plot(S~nummois,data=dataR2)
# lm1<-lm(S~nummois,data=dataR2)
# 
# 
# model1<-nls(S~(a*nummois)/(b+nummois),start=list(b=10,a=120),data=dataR2)
# 
# model2<-gam(S~s(nummois),data=dataR2)
```

# Indices Beta
## Indice de Jaccard

```{r}
#les sites sont-ils similaires entre eux? 
#Indice de Jaccard entre 0 (pas de similarité) et 1 (sites identiques)
#correspond aux nombres d'observations dans les deux sites / par le nombre dans chaque site

dataR2=dataR %>%
  filter(!Date_courte=="2021-01") %>%
  filter(Site=="Bu") %>%
  select(spp,Site) %>% 
  distinct() %>% 
  group_by(spp,Site) %>% 
  summarize(S=n()) 

dataR3=dataR %>% 
  filter(!Structure2 == "Holes") %>% 
  filter(!Date_courte=="2021-01") %>%
  filter(Site=="Bi") %>%
  select(spp,Site) %>% 
  distinct() %>% 
  group_by(spp,Site) %>% 
  summarize(S=n()) 

#pour faire avec les données spp
library(stringdist)
library(bayesbio)
stringdist(dataR3[,1],dataR2[,1],method='jaccard')#converti les caractères en données utitilisable
jaccardSets(dataR2[,1],dataR3[,1])

#pour faire avec les données spp.ID
dataR2$spp.ID<-as.numeric(dataR2$spp.ID)
dataR3$spp.ID<-as.numeric(dataR3$spp.ID)
jaccard <- function(a, b) {
    intersection = length(intersect(a, b))
    union = length(a) + length(b) - intersection
    return (intersection/union)
}

jaccard(dataR2[,-c(2:3)],dataR3[,-c(2:3)])

```

##Indice de Sorensen
```{r}
#les sites sont-ils similaires entre eux? 
#Indice de Sorensen entre 0 (pas de similarité) et 1 (sites identiques)

dataR2=dataR %>%
  filter(!Date_courte=="2021-01") %>%
  filter(Site=="Bu") %>%
  select(spp.ID,Site) %>% 
  distinct() %>% 
  group_by(spp.ID,Site) %>%
  summarize(S=n())


dataR3=dataR %>% 
  filter(!Date_courte=="2021-01") %>%
  filter(Site=="Fe") %>%
  select(spp.ID,Site) %>% 
  distinct() %>% 
  group_by(spp.ID,Site) %>% 
  summarize(S=n()) 


#pour faire avec les données spp.ID
dataR2$spp.ID<-as.numeric(dataR2$spp.ID)
dataR3$spp.ID<-as.numeric(dataR3$spp.ID)
sorensen <- function(a, b) {
    intersection = 2*length(intersect(a, b))
    union = length(a) + length(b)
    return (intersection/union)
}

sorensen(dataR2[,2],dataR3[,2])

```

## Indice de Simpson
```{r}

library(vegan)

dataR3=dataR %>% 
  filter(!Structure2 == "Holes") %>% 
  filter(Date_courte=="2021-04") %>%
  filter(Quad2=="Q1") %>%
  filter(Site=="Fe") %>%
  select(spp.ID,Site,Count,Micro) %>% 
  distinct() %>% 
  group_by(spp.ID,Site,Count,Micro) %>% 
  summarize(S=n())

specnumber(dataR3)
bci_sub_e<-vegan::diversity(dataR3,index="simpson")

```

# Matrice de distance
```{r}
# Permet de calculer la distance entre le recouvrement de chaque espèce et le taux de recouvrement

levels(factor(dataR$Site))
# test=data_PQ_light %>% filter(Site=='DSC')


# data_comp2=data_PQ_light %>% ungroup %>% 
#   select(spp,Cov,Site,Micro,Date_courte,Structure2,Strcut_groups, Quad2) %>% 
#   filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte')) %>%
# <<<<<<< HEAD
#   filter(!Structure2 %in% c('Dome','Holes','Upper_slots','Inner_slots')) %>% 
#   group_by(spp,Site,Micro,Date_courte,Structure2) %>% 
# =======
#   filter(!Structure2 %in% c('Dome','Upper_slots' )) %>% 
#     filter(!Site %in% c('Fe','DSC' )) %>% 
#   mutate(Sample=paste0(Site,'_',Date_courte,'_',
#                        Micro,'_',Quad2)) %>% 
#   group_by(Sample,Site,spp, Micro,Structure2,Strcut_groups, Date_courte) %>% 
#   dplyr::summarize(Mcov=mean(Cov)) %>% 
# 
#   group_by(Sample,Site,Micro,Date_courte,Structure2) %>% 
# >>>>>>> d7a3076aa8c86cd4609b46ec0f575f800cd1d573
#   distinct() %>% drop_na() %>% 
#     spread(spp,Mcov) %>% ungroup() %>% 
#       mutate(across(everything(.), ~replace_na(., 0))) 



data_comp2=dataR %>% ungroup %>% 
  filter(!Date_courte == '2021-01') %>% 
  select(spp,Mcov,Site,Micro,Date_courte,Structure2) %>% 
  group_by(spp,Site,Micro,Date_courte,Structure2) %>% 
  distinct() %>% drop_na() %>% 
  spread(spp,Mcov) %>% ungroup() %>% 
  mutate(across(everything(.), ~replace_na(., 0))) 

data_comp2$nouvelle<-ifelse(data_comp2$Structure2 == "Pillars" | data_comp2$Structure2 == "Columns", "Pillars", "Autres")
# data_comp2$nouvelle<-ifelse(data_comp2$Structure2 == "Pillars", "Pillars", "Autres")


# test=data_comp2 %>% filter(Site == 'VB',
                          # Date_courte=='2021-07' )
# data_comp2=data_comp2[rowSums(data_comp2)>0,]


# Comp_mat=data_comp2 %>% select(-c(Site,Sample,Micro,Structure2,Strcut_groups,Date_courte)) %>% as.matrix() 
# Meta_data=data_comp2 %>% select(Site,Sample,Micro,Structure2,Strcut_groups,Date_courte)

Comp_mat=data_comp2 %>% select(-c(Site,Micro,Structure2,Date_courte)) %>% as.matrix() 
Meta_data=data_comp2 %>% select(Site,Micro,Structure2,Date_courte) #créer jeu de données avec les méta données
# Comp_mat=data_comp2 %>% select(-c(Site,Micro,Structure2,Date_courte,nouvelle)) %>% as.matrix() 
# Meta_data=data_comp2 %>% select(Site,Micro,Structure2,Date_courte,nouvelle) #créer jeu de données avec les méta données

distdataR<-vegdist(Comp_mat, method='bray') #library vegan - distance de Bray-Curtis, considéré face aux distances euclidiennes comme plus efficace pour les données écologiques


```

##  PCoA
```{r}
# Permet de représenter les données dans l'espace et voir les paramètres expliquant le plus la variance

pcoa_tot_SS<- cmdscale(d = as.matrix(distdataR),k=10, eig = T) 
x=pcoa_tot_SS$points[,1]
y=pcoa_tot_SS$points[,2]

plot(x,y) # <- ça fonctionne

# <<<<<<< HEAD
# 
# # Data frame pour rassembler les coordonnées de la PCOA + les metadata
# PCOA_df=data.frame(x=pcoa_tot_SS$points[,1],y=pcoa_tot_SS$points[,2],
#            Structure=Meta_data$Structure2,
# =======
#  Eig=pcoa_tot_SS$eig[1:2]/sum(pcoa_tot_SS$eig)
# 
# # Pour mieux explorer le nuage de point on va passer par ggplot2.
# # Data frame pour rassembler les coordonnées de la PCOA + les metadata
# PCOA_df=data.frame(x=pcoa_tot_SS$points[,1],y=pcoa_tot_SS$points[,2],
#            Struc=Meta_data$Structure2,
#            Struc_group=Meta_data$Strcut_groups,
# >>>>>>> d7a3076aa8c86cd4609b46ec0f575f800cd1d573
#            Site=Meta_data$Site,
#            Date=Meta_data$Date_courte)
# 
# 
# <<<<<<< HEAD
#  ggplot(data=PCOA_df,aes(x,y, col=Date))+ # <- Ici on explore avec col les variable qui explique le + l'explosion du nuage de points
#    # geom_point(aes(col=Site), size=1, alpha=.6)+
#     geom_point()+
#    labs(x="Axe 1 (temporalité)",y="Axe 2")+
#  geom_hline(yintercept=0)+
#    geom_vline(xintercept=0)+
#    theme_bw()
# =======
# 
# PCOA_df_mean=PCOA_df %>% group_by(Struc_group) %>% 
#   summarize(Mx=mean(x),
#             My=mean(y))
# 
# ggplot(data=PCOA_df,aes(x,y, col=Struc_group))+ # <- Ici on explore avec col les variable qui explique le + l'explosion du nuage de points
#   # geom_point(aes(col=Site), size=1, alpha=.6)+
#   geom_point()+
#   geom_point(data=PCOA_df_mean,aes(Mx,My), size=5)+
#   geom_hline(yintercept=0)+
#   geom_vline(xintercept=0)+
#   theme_bw()

 PCOA_df=data.frame(x=pcoa_tot_SS$points[,1],y=pcoa_tot_SS$points[,2],
                   Structure=Meta_data$Structure2,
                   Site=Meta_data$Site,
                   Date=Meta_data$Date_courte
                   # Structure3=Meta_data$nouvelle
                    )
# res<-prcomp(PCOA_df[,c(1:2)],center=T,scale=T)
# 
# fviz_pca_ind(res,geom.ind='point',col.ind=groupes,addEllipses = T)


ggplot(data=PCOA_df,aes(x,y, col=Structure))+ # <- Ici on explore avec col les variable qui explique le + l'explosion du nuage de points
  # geom_point(aes(col=Site), size=1, alpha=.6)+
  geom_point()+
  labs(x="Axe 1 (temporalité)",y="Axe 2")+
  geom_hline(yintercept=0)+
  geom_vline(xintercept=0)+
  theme_bw()
  # geom_mark_ellipse(aes(fill=Structure,group=Structure))

res <- prcomp(PCOA_df, center = TRUE, scale = TRUE)
pander(factoextra::get_eig(res))

groupes <- data_comp2$Structure2


# apport de la variabilité selon le nombre d'axe
summaryPCOA<-data.frame(
  EIG= pcoa_tot_SS$eig,
  PCTVAR=100*pcoa_tot_SS$eig/sum(pcoa_tot_SS$eig),
  CUMPCTVAR = cumsum(100*pcoa_tot_SS$eig/sum(pcoa_tot_SS$eig)))

plot(summaryPCOA$PCTVAR[1:30],ylim=c(0,25),
        xlab="Composantes",ylab="Pourcentage d'inertie (explication de la variance)")

```

## Permanova
```{r}
# Permet de voir s'il y a possibilité de regrouper les structures

data_comp2=dataR %>% ungroup %>% 
  filter(!Date_courte == '2021-01') %>% 
  select(spp,Mcov,Site,Micro,Date_courte,Structure2) %>% 
  group_by(spp,Site,Micro,Date_courte,Structure2) %>% 
  distinct() %>% drop_na() %>% 
  spread(spp,Mcov) %>% ungroup() %>% 
  mutate(across(everything(.), ~replace_na(., 0))) 

distdataR<-vegdist(Comp_mat, method='bray')

adonis2(distdataR~Structure2,data=data_comp2,permutations=999)


# Pair wise permanova 
groupe<-data_comp2$Structure2
groupe<-data_comp2$Site
groupe<-data_comp2$Date_courte

pairwise.adonis(distdataR,groupe,perm=999,sim.method = 'bray',p.adjust.m='bonferroni')
adonis3<-permanova_pairwise(distdataR,groupe,permutations=999,method='bray',padj="bonferroni")

pv<-adonis3$p.adj
pv<-c(0,)
Site<-adonis3$pairs
Site<-c("Colonnes","Disques","Dome","Pillars")
table(pv,Site)
Sitepv<-cbind(site,pv)

heatmap(as.matrix(as.numeric(adonis3$p.adj)))
site<-c("Disques","Colonnes","Dome","Pilliers")

Sitepv<-cbind(site,pv)

```

## ANOSIM
```{r}
#Similaire à une ANOVA mais utilise une matrice de dissimilarité en entrée de data

data_comp2=dataR %>% ungroup %>% 
  filter(!Date_courte == '2021-01') %>% 
  select(spp,Mcov,Site,Micro,Date_courte,Structure2) %>% 
  group_by(spp,Site,Micro,Date_courte,Structure2) %>% 
  distinct() %>% drop_na() %>% 
  spread(spp,Mcov) %>% ungroup() %>% 
  mutate(across(everything(.), ~replace_na(., 0))) 

datano=data_comp2[,-c(1:4)] %>% as.matrix()

ano=anosim(datano,data_comp2$Date_courte,distance="bray",permutations=999)
ano 
plot(ano)
```


# Courbe d'accumulation
## Méthode 1 (intrapolation)
```{r}
#Permet de savoir le nombre de taxon retrouvé selon l'effort d'inventaire
# Courbe d'accumulation package vegan (seulement intrapolation)

data_comp2=data_PQ_light %>% ungroup %>% 
  select(spp,Mcov,Site,Micro,Date_courte,Structure2) %>% 
  filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte'),) %>%
  filter(Structure2 == "Pillars") %>% 
  filter(Site == "Bi")%>%
    filter(Date_courte %in% c("2022-07")) %>% 

  # filter(Date_courte %in% c("2022-07","2022-04","2022-11","2022-01"))%>%
  group_by(spp,Site,Micro,Date_courte,Structure2) %>% 
  distinct() %>% drop_na() %>% 
    spread(spp,Mcov) %>% ungroup() %>% 
      mutate(across(everything(.), ~replace_na(., 0))) 

Comp_mat2=data_comp2 %>% ungroup() %>%  select(-c(Site,Micro,Structure2,Date_courte)) %>% as.matrix() 

data_comp3=data_PQ_light %>% ungroup %>% 
  select(spp,Mcov,Site,Micro,Date_courte,Structure2) %>% 
  filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte')) %>%
  filter(Structure2 == "Pillars") %>% 
  filter(Site == "Bu")%>%
  # filter(Date_courte %in% c("2022-07","2022-04","2022-11","2022-01"))%>%
  group_by(spp,Site,Micro,Date_courte,Structure2) %>% 
  distinct() %>% drop_na() %>% 
    spread(spp,Mcov) %>% ungroup() %>% 
      mutate(across(everything(.), ~replace_na(., 0))) 

Comp_mat3=data_comp3 %>% select(-c(Site,Micro,Structure2,Date_courte)) %>% as.matrix() 


data_comp4=data_PQ_light %>% ungroup %>% 
  select(spp,Mcov,Site,Micro,Date_courte,Structure2) %>% 
  filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte')) %>%
  filter(Structure2 == "Pillars") %>% 
  filter(Site == "VB")%>%
  filter(Date_courte %in% c("2022-07","2022-04","2022-11","2022-01"))%>%
  group_by(spp,Site,Micro,Date_courte,Structure2) %>% 
  distinct() %>% drop_na() %>% 
    spread(spp,Mcov) %>% ungroup() %>% 
      mutate(across(everything(.), ~replace_na(., 0))) 

Comp_mat4=data_comp4 %>% select(-c(Site,Micro,Structure2,Date_courte)) %>% as.matrix() 


data_comp5=data_PQ_light %>% ungroup %>% 
  select(spp,Mcov,Site,Micro,Date_courte,Structure2) %>% 
  filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte')) %>%
  filter(Structure2 == "Pillars") %>% 
  filter(Site == "Fe")%>%
  filter(Date_courte %in% c("2022-07","2022-04","2022-11","2022-01"))%>%
  group_by(spp,Site,Micro,Date_courte,Structure2) %>% 
  distinct() %>% drop_na() %>% 
    spread(spp,Mcov) %>% ungroup() %>% 
      mutate(across(everything(.), ~replace_na(., 0))) 

Comp_mat5=data_comp5 %>% select(-c(Site,Micro,Structure2,Date_courte)) %>% as.matrix() 


spBi<-specaccum(Comp_mat2)
spBu<-specaccum(Comp_mat3)
spVB<-specaccum(Comp_mat4)
spFe<-specaccum(Comp_mat5)


plot(spBi,col="blue",ci.type="poly",ci.lty=0,ci.col="lightblue",ylim=c(0,30),xlim=c(0,12),ylab="Nombre d'espèces",xlab="Nombre de mesures",main="Courbe accumulative taxons 2022 pilliers/Site")
par(new=T)
plot(spBi2,col="darkgreen",ci.type="poly",ci.lty=0,ci.col="lightgreen",ylim=c(0,30),xlim=c(0,12),ylab="",xlab="")
par(new=T)
plot(spBi3,col="orange",ci.type="poly",ci.lty=0,ci.col="lightyellow",ylim=c(0,30),xlim=c(0,12),ylab="",xlab="")
par(new=T)
plot(spBi4,col="red",ci.type="poly",ci.lty=0,ci.col="#FCBBA1",ylim=c(0,30),xlim=c(0,12),ylab="",xlab="")
par(new=T)
plot(spBi5,col="black",ci.type="poly",ci.lty=0,ci.col="grey",ylim=c(0,30),xlim=c(0,12),ylab="",xlab="")

legend(x = "bottomright", legend = c("Bi","VB","Fe","Bu"),lty = 1, col = c("blue","darkgreen","orange","red"),lwd = 2)

#permet de voir les indices tels que chao/ bootstrap,....
pool<-specpool(Comp_mat2)
poolaccum(Comp_mat2,permutation=100)
plot(poolaccum(Comp_mat3,permutation=100))

estimateR(as.integer(Comp_mat2))
estimateR(as.integer(Comp_mat3))
estimateR(as.integer(Comp_mat4))
estimateR(as.integer(Comp_mat5))

```

## Méthode 2 (intra et extrapolation)


### test Bruno

J'ai ici repris le package iNext pour tester avec les matrices d'incidence (P/A par structure + Mois).
La difficulté est ici est de produire une liste contenant la matrice d'incidence de chaque site. C'est le seul format qui est accepté.

Donc voilà un exemple avec le "Disc"

Contrairement à ce que je pensais, il est plus judicieux d'évaluer le nombre total de taxons sur l'ensemble du suivi, même si je suis conscient que les différences peuvent également être liées à des différence dans le suivi des différents sites...

Donc, soit on souhaite rester parcimonieux et on ne selectionne que les dates où tous les sites ont bien été échantillonnés soit on considère toutes les dates ...

```{r}
#Création d'une matrice d'incidence

# On réorganise le df de base
# Ajout d'une variable qui combine la date et la structure

### Disques
data_comp1=data_PQ_light %>% ungroup %>% 
  select(spp,Date_courte,Site,Structure2, Code_struct) %>% 
   filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte','None')) %>%
  mutate(date_st=paste0(Date_courte,'_',Code_struct)) %>%  # 
  filter(Structure2 == ("Disc")) %>%
  mutate(P=1) %>% 
    select(-c(Date_courte,Code_struct)) %>% 
  distinct() %>% group_by(Site) %>% 
  group_split()

# On créait une fonction pour nettoyer l'intérieur de la liste
fun_clean=function(x){
  x %>% spread(date_st,P) %>% 
    select(-c(spp,Site,Structure2)) %>% 
      mutate(across(everything(.), ~replace_na(., 0))) %>% 
  as.data.frame()}

# Convertion de split df en list
comp_list=as.list(data_comp1)

# Application de la fonction + names
comp_list_clean=lapply(comp_list, fun_clean)
names(comp_list_clean)<-c('Bi','Bu','Fe','Vb')

# Fonction
out.raw <- iNEXT(comp_list_clean,q=0,
                 datatype="incidence_raw",
                 endpoint=80)
plot(out.raw)

# Ici tu les données concernant l'estimation de la rich. totale
Rar_disc_df=as.data.frame(out.raw$AsyEst)



### Colonnes
data_comp1=data_PQ_light %>% ungroup %>% 
  select(spp,Date_courte,Site,Structure2, Code_struct) %>% 
   filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte','None')) %>%
  mutate(date_st=paste0(Date_courte,'_',Code_struct)) %>%  # 
  filter(Structure2 == ("Columns")) %>% 
  mutate(P=1) %>% 
    select(-c(Date_courte,Code_struct)) %>% 
  distinct() %>% group_by(Site) %>% 
  group_split()

# On créait une fonction pour nettoyer l'intérieur de la liste
fun_clean=function(x){
  x %>% spread(date_st,P) %>% 
    select(-c(spp,Site,Structure2)) %>% 
      mutate(across(everything(.), ~replace_na(., 0))) %>% 
  as.data.frame()}

# Convertion de split df en list
comp_list=as.list(data_comp1)

# Application de la fonction + names
comp_list_clean=lapply(comp_list, fun_clean)
names(comp_list_clean)<-c('Bi','Bu','Fe','Vb')

# Fonction
out.raw <- iNEXT(comp_list_clean,q=0,
                 datatype="incidence_raw",
                 endpoint=80)
plot(out.raw)
# Ici tu les données concernant l'estimation de la rich. totale
Rar_disc_df=as.data.frame(out.raw$AsyEst)



### Pilliers
data_comp1=data_PQ_light %>% ungroup %>% 
  select(spp,Date_courte,Site,Structure2, Code_struct) %>% 
   filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte','None')) %>%
  mutate(date_st=paste0(Date_courte,'_',Code_struct)) %>%  # 
  filter(Structure2 == ("Pillars")) %>% 
  mutate(P=1) %>% 
    select(-c(Date_courte,Code_struct)) %>% 
  distinct() %>% group_by(Site) %>% 
  group_split()

# On créait une fonction pour nettoyer l'intérieur de la liste
fun_clean=function(x){
  x %>% spread(date_st,P) %>% 
    select(-c(spp,Site,Structure2)) %>% 
      mutate(across(everything(.), ~replace_na(., 0))) %>% 
  as.data.frame()}

# Convertion de split df en list
comp_list=as.list(data_comp1)

# Application de la fonction + names
comp_list_clean=lapply(comp_list, fun_clean)
names(comp_list_clean)<-c('Bi','Bu','Fe','Vb')

# Fonction
out.raw <- iNEXT(comp_list_clean,q=0,
                 datatype="incidence_raw",
                 endpoint=80)
plot(out.raw)

# Ici tu les données concernant l'estimation de la rich. totale
Rar_disc_df=as.data.frame(out.raw$AsyEst)


### Structures externes
data_comp1=data_PQ_light %>% ungroup %>% 
  select(spp,Date_courte,Site,Structure2, Code_struct) %>% 
   filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte','None')) %>%
  mutate(date_st=paste0(Date_courte,'_',Code_struct)) %>%  # 
  filter(Structure2 %in% c("Disc","Pillars","Columns")) %>% 
  mutate(P=1) %>% 
    select(-c(Date_courte,Code_struct)) %>% 
  distinct() %>% group_by(Site) %>% 
  group_split()

# On créait une fonction pour nettoyer l'intérieur de la liste
fun_clean=function(x){
  x %>% spread(date_st,P) %>% 
    select(-c(spp,Site,Structure2)) %>% 
      mutate(across(everything(.), ~replace_na(., 0))) %>% 
  as.data.frame()}

# Convertion de split df en list
comp_list=as.list(data_comp1)

# Application de la fonction + names
comp_list_clean=lapply(comp_list, fun_clean)
names(comp_list_clean)<-c('Bi','Bu','Fe','Vb')

# Fonction
out.raw <- iNEXT(comp_list_clean,q=0,
                 datatype="incidence_raw",
                 endpoint=150)
plot(out.raw)

# Ici tu les données concernant l'estimation de la rich. totale
Rar_disc_df=as.data.frame(out.raw$AsyEst)

```


### Test Hugo
```{r}
# Permet de savoir le nombre de taxon retrouvé selon l'effort d'inventaire
# Courbe d'accumulation package iNEXT (permet intrapolation et extrapolation)

data_comp5=data_PQ_light %>% ungroup %>% 
  select(spp,Date_courte,Site,Structure2) %>% 
   filter(!spp %in% c('NA','NI', 'Unassigned','ponte','Ponte','None')) %>%
  filter(Date_courte %in% c('2022-11'))%>%
  # filter(Structure2 == ("Disc"))%>%
  distinct()%>% 
  group_by(spp,Site,Structure2) %>% 
  summarize(S=n()) %>%
  na.omit() 

data_comp6<- spread(data_comp5,key=Site,value=S) %>% ungroup() %>% 
      mutate(across(everything(.), ~replace_na(., 0))) 

data_comp6<-data_comp6[,-c(1:2)]



out.raw <- iNEXT(as.data.frame(data_comp6),endpoint=60)
plot(out.raw)

ChaoRichness(as.data.frame(data_comp6))

# ggiNEXT(out.raw)



#### Test avec nombre de points

data_comp5=dataR %>% ungroup %>% 
  select(spp,Date_courte,Site,Structure2,MCount) %>% 
  filter(Date_courte == '2022-07')%>%
  filter(Structure2 == "Disc")%>%
  distinct()%>% 
  group_by(spp) %>% 
  # group_by(spp,MCount,Structure2,Micro) %>% 
  # summarize(S=n()) %>%
  na.omit() 


data_comp5=dataR %>% ungroup %>%
filter(Date_courte == '2021-11')%>%
  filter(Structure2 == "Pillars")
  

data_comp6=data_comp5 %>% 
  select(spp,Site,MCount,seq,Micro) %>% 
  distinct() %>% 
  group_by(spp,Site,MCount,Micro) %>%
  # summarize(MCount2=sum((MCount),group_by(spp))) %>% 
  aggregate(MCount~spp+Site,FUN=sum) %>% 
  na.omit()

data_comp6<- spread(data_comp6,key=Site,value=MCount) %>% ungroup() %>% 
      mutate(across(everything(.), ~replace_na(., 0))) %>% 
  group_by(spp)

data_comp6<-data_comp6[,-c(1)]


out.raw <- iNEXT(as.data.frame(data_comp6),endpoint=1000)
plot(out.raw)

```


# Test vitesse de colonisation 
```{r}
#Quelle est la vitesse de colonisation des milieux? 
dataR2=dataR %>% ungroup %>% 
  select(spp,Date_courte,Site,Structure2) %>% 
  filter(!Date_courte == '2021-01') %>%
  filter(Structure2 == "Disc")%>%
  filter(Site == 'Bi') %>%
  distinct()%>% 
  group_by(Date_courte) %>% 
  # group_by(spp,MCount,Structure2,Micro) %>% 
  summarize(S=n()) %>%
  na.omit() 

```

## Calcul du temps depuis l'immersion

```{r}

data_PQ_light=data_PQ_light %>% 
   mutate(Day_delta=as.numeric(difftime(Date_ok,Date_imm_ok,units='days')))

```


